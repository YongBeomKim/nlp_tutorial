{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MDX 데이터 분석하기**\n",
    "https://pypi.org/project/mdict-utils/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1 레시피 SQlite 데이터 불러오기**\n",
    "작업한 내용을 대상으로 중분류 내용 추가하기\n",
    "- 법률, 식품, 자동차 등 중분류 내용이 당장은 필요가 없어 보인다.\n",
    "- 작업을 진행하면서 필요하면 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(908,\n",
       " '가오리조림 가오리찜 가자미야채탕 가자미찜 가지냉채 가지불고기 가지선 가지오징어냉채 가지조림 가지회 각색두부전골 각색버섯덮밥 간장 갈비구이 갈비구이찜 갈비찜 갈비탕 감자가자미구이 감자갈비탕 감자고로케 감자그라땡 감자대구오븐구이 감자두부조림 감자막튀김 감자맑은국 감자밥 감자베이컨볶음 감자보트샐러드 감자볶음 감자볶음밥 감자볶음밥치즈구이 감자부침 감자새우그라땡 감')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 레시피 데이터베이스 불러오기\n",
    "from muyong.nlp import mdx_to_df\n",
    "df    = mdx_to_df('backup/recipe.db')\n",
    "menus = df.entry.values.tolist()\n",
    "len(menus), \" \".join(menus)[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88636"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_recipes = df.paraphrase.values.tolist()\n",
    "result = []\n",
    "import re\n",
    "for _ in food_recipes:\n",
    "    result += re.findall(\"[가-힣]+\", _)\n",
    "len(result), len(list(set(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9519"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Hannanum, Okt, Mecab, Komoran\n",
    "food_text = \" \".join(list(set(result)))\n",
    "food_tokens = Mecab().nouns(food_text)\n",
    "len(food_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2630"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import Text\n",
    "food_tokens_text = Text(food_tokens)\n",
    "food_nouns = [_[0]  for _ in food_tokens_text.vocab().most_common()]\n",
    "len(food_nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2 식재료 관련 데이터 찾기**\n",
    "[전은경  맛을 표현하는 단어 (2003)](https://m.blog.naver.com/PostView.nhn?blogId=seongho0805&logNo=150048557298&proxyReferer=https%3A%2F%2Fwww.google.com%2F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/nerDict.pk', 'rb') as handle:\n",
    "    nerDict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('명사', ['1', '몹시 가문 여름 하늘.']), ('명사', ['2', '몹시 가문 날씨.\\r\\n'])],\n",
       " [('명사',\n",
       "   ['1', '겨울의 차가운 하늘.', '¶ 뿌옇게 흐렸던 한천에서 희끗희끗 눈발이 날리기 시작했다.≪이원규, 훈장과 굴레≫']),\n",
       "  ('명사', ['2', ' =한절02.\\r\\n'])],\n",
       " [('명사', ['명사', '찬물이 솟는 샘.\\r\\n'])],\n",
       " [('명사', ['명사', '땀을 흘리며 헐떡거림.', '한천-하다01(汗喘--) [한ː---]']),\n",
       "  ('동사', ['동사', '땀을 흘리며 헐떡거리다.\\r\\n'])],\n",
       " [('명사', ['명사', ' =우무01. ‘우무01’, ‘우뭇가사리’로 순화.\\r\\n'])],\n",
       " [('명사', ['명사', '『인명』', '‘이재04’의 호.\\r\\n'])]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query     = \"한천\"  # 원문 내용의 확인\n",
    "q_data    = nerDict[nerDict.Text == query].Data.values.tolist()\n",
    "q_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **메뉴 데이터 N-Gram 분석**\n",
    "\n",
    "## **1 N-Gram 데이터**\n",
    "**itemIndexTemp** 를 활용하며 고유단어 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "693"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 명사 추출사전 데이터 호출\n",
    "with open(\"data/nouns_food_03-2.txt\", \"r\") as f:\n",
    "    valid_token = f.read()\n",
    "valid_token = valid_token.split(\",\")\n",
    "len(valid_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2880, '얼큰버섯전골 쥐어채볶음 매콤순대깻순볶음 돈안심꽈리장조림 짜장볶음우동')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 분석할 메뉴데이터 호출\n",
    "import pandas as pd  # 분석을 의뢰할 메뉴 데이터 [list]\n",
    "menus_muyong  = pd.read_csv('data/menu_muyong.csv', encoding='ms949')\n",
    "menus_muyong  = menus_muyong.dropna(subset=['메인1', '메인2'])\n",
    "menus_muyong  = menus_muyong.fillna('')  # NaN 값을 지운다\n",
    "tokens = []                # DataFrame 에서 Token List 추출\n",
    "for _ in menus_muyong.columns[4:]:\n",
    "    tokens += menus_muyong[_].values.tolist()\n",
    "\n",
    "import re\n",
    "from nltk import Text\n",
    "menus_muyong = re.findall(r\"[가-힣]+\", \" \".join(tokens))\n",
    "menus_muyong = list(set(menus_muyong))\n",
    "len(menus_muyong), \" \".join(menus_muyong[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본내용: 쑥갓나물\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['쑥갓나물']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메뉴 명사추출기\n",
    "menu_token  = menus_muyong[1828]\n",
    "print(\"원본내용:\", menu_token)\n",
    "from muyong.nlp import food_nouns\n",
    "food_nouns(menu_token, valid_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2 만개의 레시피 활용**\n",
    "긴 제목에서 레시피만 추출/ 나머지 구분하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['호불호 없는 토마토파스타는 역시 ~! 토마토냉파스타 ★',\n",
       " '달콤 촉촉 달걀 푸딩 만들기, 만드는 법 ( 부드러운 달걀 요리 기본 원리 )',\n",
       " '손이가요 손이가~~자꾸 손이 가는 [가지전]']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "menus_man = pd.read_csv(\"data/1000recipe.csv\", sep=\"|\")\n",
    "menus_man = menus_man.fillna('')\n",
    "menus_man = menus_man.Menu.values.tolist()\n",
    "menus_man[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본내용: 아이볶음밥 김치볶음밥 카레가루를 넣어봐요!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['볶음밥', '김치', '카레']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메뉴 명사추출기\n",
    "menu_token  = menus_man[4528]\n",
    "print(\"원본내용:\", menu_token)\n",
    "from muyong.nlp import food_nouns\n",
    "food_nouns(menu_token, valid_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Unique Token 묶음 분석**\n",
    "메뉴의 이름들 중 대표성 높은 메뉴들 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1 레시피 데이터 특징찾기**\n",
    "잡일보단 **머신러닝 분석** 으로 우선 **모델** 만들기 (30일 발표용)\n",
    "1. 구내식당은 대략 **2,300 개로** 추출 된다\n",
    "1. 만개의 레시피는 50,000개로 특징이 추출\n",
    "1. 우선은 **2,300 개** 로 **모델 사이트를 우선 만들어서 9월초 시연모델** 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2880, 2335)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 10,000 개 레시피 분석\n",
    "# result = [\"_\".join(sorted(food_nouns(menu, valid_token)))  \n",
    "#           for menu in menus_man  \n",
    "#           if \"_\".join(sorted(food_nouns(menu, valid_token)))]\n",
    "\n",
    "# result = list(sorted(set(result)))\n",
    "# len(menus_man), len(result)\n",
    "\n",
    "# Muyong 레시피 분석\n",
    "result = [\"_\".join(sorted(food_nouns(menu, valid_token)))  \n",
    "          for menu in menus_muyong  \n",
    "          if \"_\".join(sorted(food_nouns(menu, valid_token)))]\n",
    "\n",
    "result = list(sorted(set(result)))\n",
    "len(menus_muyong), len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved\n"
     ]
    }
   ],
   "source": [
    "with open(\"menus_unique_token.txt\", 'w') as f:\n",
    "    f.write(\",\".join(result))\n",
    "print(\"file saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2 네이버 레시피 데이터 수집하기**\n",
    "특징을 대상으로 네이버 블로그 데이터 대상 수집하기\n",
    "1. 저장결과를 Sqlite3 로 저장하기\n",
    "1. 안정적인 작업을 수행하도록 잘 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.1 s, sys: 1.17 s, total: 15.2 s\n",
      "Wall time: 15.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>가슴살_계란_닭_장조림</td>\n",
       "      <td>[{'title': '부드러운 닭&lt;b&gt;가슴살&lt;/b&gt; &lt;b&gt;장조림&lt;/b&gt; &lt;b&gt;만들기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>가슴살_굴소스_닭_볶음밥</td>\n",
       "      <td>[{'title': '수비드 닭&lt;b&gt;가슴살&lt;/b&gt; 요리 : 돈까스 &amp;amp; &lt;b&gt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title                                               data\n",
       "0   가슴살_계란_닭_장조림  [{'title': '부드러운 닭<b>가슴살</b> <b>장조림</b> <b>만들기...\n",
       "1  가슴살_굴소스_닭_볶음밥  [{'title': '수비드 닭<b>가슴살</b> 요리 : 돈까스 &amp; <b>..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import os, sqlite3, json, time\n",
    "con = sqlite3.connect(\"backup/foods.db\")\n",
    "\n",
    "import pandas as pd\n",
    "df         = pd.read_sql(\"select * from 'foods'\", con, index_col=None).drop('index', axis=1)\n",
    "con.close()\n",
    "food_links = df.data.values.tolist()\n",
    "df.data    = [json.loads(_) for _ in food_links] # json 디코딩\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수집값이 없는 인덱스를 새로 수정하기 \n",
    "# Token Index 값이 유용한지를 Naver OpenAPI 결과값으로 구분하는 방법도 유용할 듯!!\n",
    "index_err = [no  for no,_ in enumerate(df.data.values.tolist())  if len(_) == 0]\n",
    "token_temp_list = [\"가쓰오_어묵_유부\",\"가쓰오_유부\",\"가쓰오_유부_팽이\",\"감자_미트볼_알감자_조림\",\\\n",
    "              \"돈육_불고기_간장\",\"떡_부추_해물\",\"무침_부추_콩나물\",\"부추_전_해물\",\"오징어_탕수\"]\n",
    "\n",
    "for no, i in enumerate(index_err):\n",
    "    df.iloc[i, [0]] = token_temp_list[no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:17<00:00,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 661 ms, sys: 98 ms, total: 759 ms\n",
      "Wall time: 17.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from muyong.naver import get_blog_list\n",
    "from tqdm import tqdm\n",
    "result = {}\n",
    "for _ in tqdm(token_temp_list):\n",
    "    temp = []\n",
    "    query_token  = _+\"_만들기\"\n",
    "    for i in range(1, 500, 100):\n",
    "        temp += get_blog_list(query_token, i)['items']\n",
    "    time.sleep(.3)\n",
    "    result[_] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for no, i in enumerate(index_err):\n",
    "    df.iloc[i, 1] = result[token_temp_list[no]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save is done\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('data/naver_key_list.pk', 'wb') as handle:\n",
    "    pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(\"save is done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"menus_unique_token.txt\", \"r\") as f:\n",
    "    word_tokens = f.read().split(\",\")\n",
    "\n",
    "# get_blog_list(\"가슴살_닭_매콤_볶음_우동\"+\"_만들기\", 101)[\"items\"][:2]\n",
    "# len(word_tokens), word_tokens[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['가쓰오_어묵_유부',\n",
       " '가쓰오_유부',\n",
       " '가쓰오_유부_팽이',\n",
       " '감자_미트볼_알감자_조림',\n",
       " '돈육_불고기_간장',\n",
       " '떡_부추_해물',\n",
       " '무침_부추_콩나물',\n",
       " '부추_전_해물',\n",
       " '오징어_탕수']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[list(result.keys())[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:19<00:00,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.43 s, sys: 464 ms, total: 1.9 s\n",
      "Wall time: 20 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from muyong.naver import get_blog_list\n",
    "import time, json, os, sqlite3\n",
    "file_db = \"foods.db\"\n",
    "\n",
    "token_temp_list = [\"가쓰오_어묵_유부\",\"가쓰오_유부\",\"가쓰오_유부_팽이\",\"감자_미트볼_알감자_조림\",\\\n",
    "              \"돈육_불고기_간장\",\"떡_부추_해물\",\"무침_부추_콩나물\",\"부추_전_해물\",\"오징어_탕수\"]\n",
    "\n",
    "for _ in tqdm(token_temp_list):\n",
    "    # web link 목록 수집하기\n",
    "    result, temp = [], []\n",
    "    query_token  = _+\"_만들기\"\n",
    "    for i in range(1, 500, 100):\n",
    "        temp += get_blog_list(query_token, i)['items']\n",
    "    time.sleep(.3)\n",
    "    result.append([_, temp])\n",
    "    \n",
    "    # sqlite3 저장하기 (단어별 결과를 Json으로 저장 (list는 저장시 오류))\n",
    "    df  = pd.DataFrame(result)\n",
    "    df.columns = ['title', 'data']\n",
    "    df.data    = [ json.dumps(_)  for _ in df.data ]\n",
    "    con = sqlite3.connect(file_db)\n",
    "    df.to_sql('foods', con, if_exists='append')\n",
    "    con.commit()\n",
    "    time.sleep(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>오징어_탕수</td>\n",
       "      <td>[{\"title\": \"[\\ub3c4\\uc2dd\\ub2f9]&lt;b&gt;\\ud0d5\\uc21...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    title                                               data\n",
       "0  오징어_탕수  [{\"title\": \"[\\ub3c4\\uc2dd\\ub2f9]<b>\\ud0d5\\uc21..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3 링크 url 데이터만 저장하기**\n",
    "**API 수집결과 중 Link Url** 만 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>가슴살_계란_닭_장조림</td>\n",
       "      <td>[{'title': '부드러운 닭&lt;b&gt;가슴살&lt;/b&gt; &lt;b&gt;장조림&lt;/b&gt; &lt;b&gt;만들기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>가슴살_굴소스_닭_볶음밥</td>\n",
       "      <td>[{'title': '수비드 닭&lt;b&gt;가슴살&lt;/b&gt; 요리 : 돈까스 &amp;amp; &lt;b&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>가슴살_닭_라이스_카레</td>\n",
       "      <td>[{'title': '닭의품격 초간편 냉동닭&lt;b&gt;가슴살&lt;/b&gt; &lt;b&gt;카레&lt;/b&gt;&lt;b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title                                               data\n",
       "0   가슴살_계란_닭_장조림  [{'title': '부드러운 닭<b>가슴살</b> <b>장조림</b> <b>만들기...\n",
       "1  가슴살_굴소스_닭_볶음밥  [{'title': '수비드 닭<b>가슴살</b> 요리 : 돈까스 &amp; <b>...\n",
       "2   가슴살_닭_라이스_카레  [{'title': '닭의품격 초간편 냉동닭<b>가슴살</b> <b>카레</b><b..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('backup/naver_api_org.pk', 'rb') as handle:\n",
    "    df = pickle.load(handle)\n",
    "\n",
    "# data 에서 naver 링크만 찾아서 정리하기\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2335/2335 [00:00<00:00, 4736.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>가슴살_계란_닭_장조림</td>\n",
       "      <td>https://blog.naver.com/berry__chu?Redirect=Log...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>가슴살_굴소스_닭_볶음밥</td>\n",
       "      <td>https://blog.naver.com/happyday82?Redirect=Log...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>가슴살_닭_라이스_카레</td>\n",
       "      <td>https://blog.naver.com/hogengggy?Redirect=Log&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>가슴살_닭_매콤_볶음_우동</td>\n",
       "      <td>https://blog.naver.com/cutylee82?Redirect=Log&amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>가슴살_닭_볶음밥_파인애플</td>\n",
       "      <td>https://blog.naver.com/aurelly3280?Redirect=Lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title                                               data\n",
       "0    가슴살_계란_닭_장조림  https://blog.naver.com/berry__chu?Redirect=Log...\n",
       "1   가슴살_굴소스_닭_볶음밥  https://blog.naver.com/happyday82?Redirect=Log...\n",
       "2    가슴살_닭_라이스_카레  https://blog.naver.com/hogengggy?Redirect=Log&...\n",
       "3  가슴살_닭_매콤_볶음_우동  https://blog.naver.com/cutylee82?Redirect=Log&...\n",
       "4  가슴살_닭_볶음밥_파인애플  https://blog.naver.com/aurelly3280?Redirect=Lo..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "from tqdm import tqdm\n",
    "for datum in tqdm(df.data.values.tolist()):\n",
    "    temp = []\n",
    "    for _ in datum:  # 500개 개별확인\n",
    "        if _['link'].find(\"https://blog.naver.com/\") != -1:\n",
    "            temp.append(_['link'])\n",
    "    result.append(\"|\".join(temp))\n",
    "df.data = result\n",
    "df.to_csv('data/naver_links.csv', index=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Today\n",
    "# 단어 Token 을 나열된 순서대로 정리하여 문법구조 분석 알고리즘 적용\n",
    "# CFG 와 유사한 방식으로 불필요한 단어 및 묶음 정리하기\n",
    "# 묶음 기준을 설정한 뒤, 크롤링을 통해 단어별 문서 300개를 수집 분석하여 연관단어 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "명엽채(명태채)/청포북(녹두묵)\n",
    "\n",
    "1. 석박지/무석박지\n",
    "\n",
    "```\n",
    "마요 => 마요네즈\n",
    "소시지 => 소세지\n",
    "꺳잎 => 깻잎\n",
    "게란 => 계란\n",
    "배춧 => 배추\n",
    "불낙 => 낙지\n",
    "콘 => 옥수수\n",
    "돈 => 돼지\n",
    "탕수 => 탕수육\n",
    "우무 => 우묵\n",
    "중국식/\n",
    "한국식/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/nerDict.pk', 'wb') as handle:\n",
    "    pickle.dump(nerDict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('data/nerDict.pk', 'rb') as handle:\n",
    "    nerDict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Naver Post Detail Crawling**\n",
    "메뉴의 이름들 중 대표성 높은 메뉴들 찾기\n",
    "\n",
    "## **1 Naver Link 목록**\n",
    "OpenAPI 로 수집한 결과값 저장된 목록 List 원본의 수정보완\n",
    "1. Naver OPEN API 결과 **Token 이 유효값인지** 확인 가능했다 (Oh!!)\n",
    "1. 네이버 블로그 목록만 정리한 DataBase 만들기\n",
    "1. 목록을 4개로 나워서 2개의 서버에서 돌리며 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# 수집결과 불필요한 기호들 제거하는 함수\n",
    "def blog_preprocess(post):\n",
    "    post_temp = post.replace('\\n',\"\").replace('\\t',\"\").split(\".\")\n",
    "    post_temp = [\" \".join(re.findall(r\"[가-힣0-9A-z]+\", _))  for _ in post_temp  if len(_.strip()) >= 1]\n",
    "    return \".\".join(post_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "links_org      = pd.read_csv('data/naver_links.csv')\n",
    "# links_org.shape, links_org.head(3)\n",
    "links_by_token = links_org.iloc[::60, :] # 길이를 절반으로 축소\n",
    "links_by_token = links_by_token.data.values.tolist()\n",
    "len(links_by_token), links_by_token[0][:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3, time, os, requests_cache\n",
    "file_db = \"naver.db\"\n",
    "conn = sqlite3.connect(file_db)\n",
    "requests_cache.install_cache('cache')\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from muyong.util import Telegram\n",
    "from muyong.naver import get_blog_post\n",
    "t = Telegram()\n",
    "links_length = len(links_by_token)\n",
    "for no, links in tqdm(enumerate(links_by_token)):\n",
    "    result, temp = [], []\n",
    "    links = links.split('|')\n",
    "    for _ in links[:100]:\n",
    "        _ = get_blog_post(_)\n",
    "        _ = blog_preprocess(_)\n",
    "        temp.append(_)\n",
    "        time.sleep(.1)\n",
    "    temp = \"|\".join(temp)     # 500개를 저장\n",
    "    result.append([no, temp])\n",
    "    df = pd.DataFrame(result)\n",
    "    df.to_sql('foods', conn, if_exists='append')\n",
    "    os.remove(\"cache.sqlite\")\n",
    "    if no % 200 == 0:\n",
    "        t.msg(\"{}/ {} th processing\".format(no, links_length))\n",
    "    time.sleep(.1)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2 수집결과 살펴보기**\n",
    "Sqlite 결과를 보다 활용하기 쉽게 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "conn = sqlite3.connect(\"naver.db\")\n",
    "df = pd.read_sql('SELECT * FROM \"foods\"', conn, index_col=None).drop('index', axis=1)\n",
    "conn.close()\n",
    "df = df.iloc[11:].reset_index(drop=True)\n",
    "df.columns = ['Query', 'Posts']\n",
    "df.Query = links_org.iloc[::60, 0].tolist()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/naver_posts_sample.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Query.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
