{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **자연어 5일 - Tf-IDF Ranker**\n",
    "- Document Representation : **[Source Code](http://bitly.kr/uC66hz)**\n",
    "- **[스탠포드 공대 IR 수업자료](https://nlp.stanford.edu/IR-book/newslides.html)** \n",
    "- **[버지니아 공대 NLP 수업자료](http://www.cs.virginia.edu/~hw5x/Course/IR2015/_site/lectures/)**\n",
    "\n",
    "# **PreView**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['오류', '우회', '함수', '추가', '교수', '점', '만점', '학생', '혁진', '코리아', '텍', '설문']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정규식에서 숫자는 : String Range 값을 특정 합니다\n",
    "import os, re\n",
    "fileFolder = \"./News/\" \n",
    "fileList   = [fileFolder + _  for _ in os.listdir(fileFolder) \n",
    "               if re.match(\"\\d{10}.txt\", _) ]\n",
    "\n",
    "# 네이버 뉴스 수집자료를 collection 로 묶는다\n",
    "collection = []\n",
    "for _ in fileList:\n",
    "    with open(_) as f:\n",
    "        collection.append(f.read())\n",
    "\n",
    "# DTM 자료형 생성하기\n",
    "from collections import defaultdict \n",
    "DTM = defaultdict(lambda:defaultdict(int))\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "for i, doc in enumerate(collection):\n",
    "    for term in Mecab().nouns(doc):\n",
    "        DTM[i][term] += 1\n",
    "\n",
    "# TDM 만들기 (DTM 의 활용)\n",
    "TDM = defaultdict(lambda:defaultdict(int))\n",
    "for doc, termDict in DTM.items():\n",
    "    for term, freq in termDict.items():\n",
    "        TDM[term][doc] = freq\n",
    "\n",
    "list(TDM.keys())[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 36, 72, 88, 102], [1, 10, 20, 36, 50]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DTM 을 활용한 쿼리검색\n",
    "query = \"김정은 판문점\"\n",
    "\n",
    "searchResult = []\n",
    "from nltk.tokenize import word_tokenize\n",
    "for _ in word_tokenize(query):\n",
    "    docResult = [] # collection 문서별 Token 검색결과\n",
    "    for doc, termDict in DTM.items():\n",
    "        if _ in termDict.keys():\n",
    "            docResult.append(doc)\n",
    "    searchResult.append(docResult)\n",
    "    \n",
    "# [ 김정은 검색결과,  판문점 검색결과 ]\n",
    "searchResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 36, 72, 88, 102], [1, 10, 20, 36, 50]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TDM 을 활용한 쿼리검색\n",
    "query = \"김정은 판문점\"\n",
    "\n",
    "searchResult = []\n",
    "for _ in word_tokenize(query):\n",
    "    searchResult.append(list(TDM[_].keys()))\n",
    "searchResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5431, 5430)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vocabluary or Lexicon = in-memory 에 저장(단어 => 어느문서? 위치(포인터))\n",
    "# Posting = on-disk : Huge Data (어느문서?, )\n",
    "Vocabulary       = [] # TDM 저장된 단어목록\n",
    "globalVocabulary = {} # in-Memory : 단어와 위치값\n",
    "globalPosting    = [] # on-Dist : 디스크 문서저장\n",
    "\n",
    "for i, doc in enumerate(collection):\n",
    "    localTDM = defaultdict(int) # 문서별 TDM 계산객체\n",
    "    \n",
    "    # 문서별 단어의 빈도를 기록한다.\n",
    "    for term in Mecab().nouns(doc):\n",
    "        localTDM[term] += 1\n",
    "        \n",
    "    for term, freq in localTDM.items():\n",
    "        if term not in Vocabulary:\n",
    "            Vocabulary.append(term)\n",
    "            \n",
    "        termIdx = Vocabulary.index(term)\n",
    "        \n",
    "        if termIdx not in globalVocabulary.keys():\n",
    "            nextPtr = -1 # 더이상 해당 Token 이 발견되지 않을 때\n",
    "        else:\n",
    "            nextPtr = globalVocabulary[termIdx] # \n",
    "        \n",
    "        _posting = [i, freq, nextPtr]        \n",
    "        globalVocabulary[termIdx] = len(globalPosting)\n",
    "        globalPosting.append(_posting)\n",
    "\n",
    "len(globalVocabulary), max(globalVocabulary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 1, 6830]\n",
      "[36, 3, 3738]\n",
      "[20, 1, 2097]\n",
      "[10, 1, 139]\n",
      "[1, 2, -1]\n"
     ]
    }
   ],
   "source": [
    "# Inversed Index 를 활용한 Query 검색 Tree \n",
    "query = \"판문점\"\n",
    "ptr   = globalVocabulary[Vocabulary.index(query)]\n",
    "while True:\n",
    "    if ptr < 0:\n",
    "        break\n",
    "    print(globalPosting[ptr])\n",
    "    ptr = globalPosting[ptr][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[102, 88, 72, 36, 1], [50, 36, 20, 10, 1]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TDM 모델을 활용한 Query 검색엔진\n",
    "# 검색결과를 빠르게 출력 합니다.\n",
    "query = \"김정은 판문점\"\n",
    "\n",
    "searchResult = list()\n",
    "for q in word_tokenize(query):\n",
    "    ptr = globalVocabulary[Vocabulary.index(q)]\n",
    "    _qResult = list()\n",
    "    while True:\n",
    "        _posting = globalPosting[ptr]\n",
    "        _qResult.append(_posting[0])\n",
    "        if _posting[-1] == -1:\n",
    "            break\n",
    "        ptr = _posting[-1]\n",
    "    searchResult.append(_qResult)\n",
    "\n",
    "searchResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tf IDF 를 활용한 Ranker 성능 높이기** \n",
    "- **AND NOT** 조건의 결과를 수행합니다\n",
    "- **Notion of Relevance** 관계를 활용 합니다\n",
    "- **[수업관련 Slice PDF](http://www.cs.virginia.edu/%7Ehw5x/Course/IR2015/_site/docs/PDFs/Boolean&VS%20model.pdf)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1 tf-idf Weight Measure**\n",
    "TWM : Tfidf Weight Measure : 가중치를 활용하여 Tf-idf 정규화를 진행 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 1 µs, total: 2 µs\n",
      "Wall time: 4.77 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# Voca or Lexicon = in-memory(단어=>어느 문서? 위치(포인터))\n",
    "# Posting = on-disk:huge(어느 문서, 몇 번?)\n",
    "Vocabulary = list() # 단어 목록\n",
    "globalVocabulary = dict() # 메모리, 단어-위치\n",
    "globalPosting = list() # 디스크\n",
    "maxFreq = list() # 문서별 최대빈도\n",
    "\n",
    "for i, doc in enumerate(collection):\n",
    "    localTDM = defaultdict(int)\n",
    "    for term in Mecab().nouns(doc):\n",
    "        localTDM[term] += 1\n",
    "    maxFreq.append(max(localTDM.values()))\n",
    "    \n",
    "    for term, freq in localTDM.items():\n",
    "        if term not in Vocabulary:\n",
    "            Vocabulary.append(term)\n",
    "        termIdx = Vocabulary.index(term)\n",
    "        \n",
    "        if termIdx not in globalVocabulary.keys():\n",
    "            nextPtr = -1\n",
    "        else:\n",
    "            nextPtr = globalVocabulary[termIdx]\n",
    "            \n",
    "        _posting = [i, freq, nextPtr]\n",
    "        \n",
    "        globalVocabulary[termIdx] = len(globalPosting)\n",
    "        globalPosting.append(_posting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98, 1, 13998]\n",
      "[82, 8, 10862]\n",
      "[61, 1, 10472]\n",
      "[59, 3, 7192]\n",
      "[38, 5, 7028]\n",
      "[37, 2, 5592]\n",
      "[29, 1, 4759]\n",
      "[25, 1, 4460]\n",
      "[24, 3, 4321]\n",
      "[23, 4, 1857]\n",
      "[9, 2, 4]\n",
      "[0, 12, -1]\n"
     ]
    }
   ],
   "source": [
    "ptr = globalVocabulary[Vocabulary.index(\"교수\")]\n",
    "while True:\n",
    "    if ptr < 0:\n",
    "        break\n",
    "    print(globalPosting[ptr])\n",
    "    ptr = globalPosting[ptr][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[102, 88, 72, 36, 1], [50, 36, 20, 10, 1]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchResult = list()\n",
    "for q in word_tokenize(query):\n",
    "    ptr = globalVocabulary[Vocabulary.index(q)]\n",
    "    _qResult = list()\n",
    "    while True:\n",
    "        _posting = globalPosting[ptr]\n",
    "        _qResult.append(_posting[0])\n",
    "        if _posting[-1] == -1:\n",
    "            break\n",
    "        ptr = _posting[-1]\n",
    "    searchResult.append(_qResult)\n",
    "\n",
    "searchResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2 TF IDF 만들기**\n",
    "```\n",
    "가중치 = TF * IDF\n",
    "TF = freq_ij (문서번호 J 의 i 단어의 빈도) => Posting\n",
    "----------------------------------------------\n",
    "argmax freq_j (j번째 문서에서 최대빈도를 갖는 단어) => maxFreq\n",
    "IDF = log(N => len(collection)  /  df => postring 에서 ptr 의 이동갯수)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2, sqrt\n",
    "\n",
    "globalWeight    = globalPosting\n",
    "globalDocLength = defaultdict(float)\n",
    "N = len(collection)\n",
    "\n",
    "for term in Vocabulary:\n",
    "    termIdx = Vocabulary.index(term)\n",
    "    ptr = globalVocabulary[termIdx]\n",
    "    df  = 0\n",
    "    while True: # 0:문서번호, 1:빈도, 2:위치\n",
    "        df += 1\n",
    "        _posting = globalPosting[ptr]\n",
    "        if _posting[-1] == -1:\n",
    "            break\n",
    "        ptr = _posting[-1]\n",
    "    IDF = log2(N/df)\n",
    "\n",
    "    ptr = globalVocabulary[termIdx]\n",
    "    while True: # 0:문서번호, 1:빈도, 2:위치\n",
    "        _posting = globalPosting[ptr]\n",
    "        TF = _posting[1]/maxFreq[_posting[0]]\n",
    "        WEIGHT = TF * IDF\n",
    "        _posting[1] = WEIGHT\n",
    "        globalDocLength[_posting[0]] += WEIGHT**2\n",
    "        if _posting[-1] == -1:\n",
    "            break\n",
    "        ptr = _posting[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3 Maximum tf normalization 를 활용한 Query 가중치 변환**\n",
    "- 질문 Query 를 **본문의 TF-IDF 가중치로** 변환 합니다\n",
    "- 변환된 내용을 바탕으로 본문들의 내용을 검색 합니다.\n",
    "- https://nlp.stanford.edu/IR-book/html/htmledition/maximum-tf-normalization-1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'김정은': 1, '트럼프': 2, '판문점': 1, '대한민국': 1, '대통령': 1})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 질문 Query 내용에 가중치를 적용 합니다\n",
    "query    = \"김정은 트럼프 트럼프 판문점 대한민국 대통령\"\n",
    "tokens   = word_tokenize(query)\n",
    "queryTDM = defaultdict(int)\n",
    "for _ in tokens:\n",
    "    queryTDM[_] += 1\n",
    "    \n",
    "print(queryTDM)\n",
    "queryMax = max(queryTDM.values())\n",
    "queryMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {133: 3.273429324221892,\n",
       "             131: 3.6865005271832185,\n",
       "             135: 3.273429324221892,\n",
       "             2164: 2.9093592038442107,\n",
       "             132: 1.773429324221892})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maximum tf normalization  \n",
    "a = 0.5\n",
    "queryWeight = defaultdict(float)\n",
    "for t, f in queryTDM.items():\n",
    "    TF = a + (1-a)*(f/queryMax)\n",
    "    \n",
    "    if t in Vocabulary:\n",
    "        termIdx = Vocabulary.index(t)\n",
    "        ptr = globalVocabulary[termIdx]\n",
    "        df = 0\n",
    "        while True:# 0:문서번호, 1:빈도, 2:위치\n",
    "            df += 1\n",
    "            _posting = globalPosting[ptr]\n",
    "            if _posting[-1] == -1:\n",
    "                break\n",
    "            ptr = _posting[-1]\n",
    "        IDF = log2(N/df)\n",
    "        \n",
    "        queryWeight[termIdx] = TF * IDF\n",
    "\n",
    "queryWeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {102: 2.041017055366818,\n",
       "             88: 0.6211791038072924,\n",
       "             72: 2.640074496892554,\n",
       "             36: 11.662111860061826,\n",
       "             1: 7.7125794934897085,\n",
       "             98: 4.057051564832064,\n",
       "             66: 1.270263444828736,\n",
       "             50: 2.672567301264168,\n",
       "             23: 4.939913396556195,\n",
       "             10: 17.56515267510014,\n",
       "             3: 0.6471564827105785,\n",
       "             20: 0.6494145176167146,\n",
       "             93: 3.761942656441342,\n",
       "             83: 0.47024283205516776,\n",
       "             75: 1.0259843608476387,\n",
       "             68: 4.837629599116536,\n",
       "             63: 0.38916648170082846,\n",
       "             29: 0.49068817257930547,\n",
       "             21: 0.40306528461871516,\n",
       "             82: 1.0483505226700387,\n",
       "             77: 4.193402090680155,\n",
       "             65: 1.397800696893385,\n",
       "             61: 0.4659335656311283,\n",
       "             60: 0.19060918594000706,\n",
       "             53: 1.630767479708949,\n",
       "             46: 2.79560139378677,\n",
       "             27: 0.4659335656311283,\n",
       "             16: 2.935381463476108,\n",
       "             9: 1.7741316537492964,\n",
       "             6: 0.9318671312622566})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "searchResult = defaultdict(float)\n",
    "for termIdx, w in queryWeight.items():\n",
    "    ptr = globalVocabulary[termIdx]\n",
    "    while True:\n",
    "        _posting = globalWeight[ptr]\n",
    "        searchResult[_posting[0]] += w * _posting[1]\n",
    "        if _posting[-1] == -1:\n",
    "            break\n",
    "        ptr = _posting[-1]\n",
    "searchResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 1.7442066672042902),\n",
       " (36, 1.3463475558358595),\n",
       " (1, 1.3012906467221494),\n",
       " (23, 0.9910971611357137),\n",
       " (68, 0.5127828369217432),\n",
       " (98, 0.37401743610938953),\n",
       " (46, 0.3314082243996938),\n",
       " (77, 0.3277533399319457),\n",
       " (9, 0.30679076970660785),\n",
       " (50, 0.3055149067722887)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for docIdx, innerProduct in searchResult.items():\n",
    "    cosine = innerProduct / sqrt(globalDocLength[docIdx])\n",
    "    searchResult[docIdx] = cosine\n",
    "\n",
    "# 여러 문서 중 유사도가 측정 가능한 문서를 출력\n",
    "sorted(searchResult.items(),\n",
    "       key=lambda x:x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **유클리드를 활용한 문서 유사도 측정**\n",
    "## **1 문서의 유사도 측정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchResult = defaultdict(float)\n",
    "\n",
    "for termIdx, w in globalVocabulary.items():\n",
    "    x1 = queryWeight[termIdx]\n",
    "    ptr = globalVocabulary[termIdx]\n",
    "    while True:\n",
    "        _posting = globalWeight[ptr]\n",
    "        x2 = _posting[1]\n",
    "        searchResult[_posting[0]] += (x1-x2)**2\n",
    "        if _posting[-1] == -1:\n",
    "            break\n",
    "        ptr = _posting[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 23.16127843575197 532\n",
      "92 25.08825678218501 271\n",
      "78 25.578752499231122 346\n",
      "11 27.8320122977396 489\n",
      "62 30.699300074065857 343\n",
      "67 30.787153255780606 790\n",
      "23 31.698634856611957 445\n",
      "9 33.03839312512632 491\n",
      "83 35.42540452205284 496\n",
      "60 36.4422161208503 672\n",
      "27 36.66022886089046 582\n",
      "80 37.06793333606439 296\n",
      "21 38.239963708726584 685\n",
      "66 39.47964657597552 221\n",
      "69 39.51761398514184 261\n",
      "63 39.88226758441258 774\n",
      "71 40.78502347796054 366\n",
      "38 43.35218783200697 608\n",
      "58 45.991269988408696 618\n",
      "3 50.09325114238466 543\n",
      "22 54.83530278935449 443\n",
      "48 55.234858979186455 361\n",
      "20 55.5089593763493 670\n",
      "85 56.23029723514068 508\n",
      "1 57.86863667014972 1719\n",
      "24 59.54133146601639 393\n",
      "6 59.69971353622258 234\n",
      "2 61.038445727461074 547\n",
      "102 62.06481096418527 163\n",
      "49 64.03811769339039 398\n",
      "88 66.33594952021336 576\n",
      "64 66.38455681770154 366\n",
      "82 67.2383617652981 608\n",
      "29 67.66764339366878 805\n",
      "26 67.70880741913804 304\n",
      "46 68.7118815105101 362\n",
      "61 69.71111640616816 228\n",
      "94 69.79552632700982 333\n",
      "47 72.18911488820645 303\n",
      "19 74.04579640385506 438\n",
      "44 74.5861093278434 161\n",
      "0 76.72093453235026 334\n",
      "55 76.8370571759133 467\n",
      "37 80.14447700487051 416\n",
      "59 80.80496994123051 440\n",
      "42 80.83932318633738 459\n",
      "75 84.50683210058568 286\n",
      "18 85.76419692248379 717\n",
      "97 86.5958393961312 600\n",
      "31 87.75095642433232 965\n",
      "100 89.13589186869291 303\n",
      "36 89.87267183478184 404\n",
      "68 90.93585559518397 369\n",
      "14 92.45690627582246 227\n",
      "10 93.7367212873786 520\n",
      "7 94.14855260280527 388\n",
      "50 98.62863121932955 363\n",
      "95 100.09259440284514 579\n",
      "87 100.67254118760351 463\n",
      "13 101.45232031818982 239\n",
      "28 102.38610281311098 451\n",
      "56 103.29705463899309 427\n",
      "54 110.99506839468016 255\n",
      "53 112.6858527147923 1005\n",
      "89 115.51420276144334 264\n",
      "52 117.82907323475364 333\n",
      "99 118.21858079072936 511\n",
      "57 120.27368456681678 397\n",
      "72 123.71645040493134 319\n",
      "73 126.2700341758943 218\n",
      "98 126.28354109993899 2163\n",
      "15 135.19621735689847 394\n",
      "70 137.54984759895612 255\n",
      "65 137.76390802899334 565\n",
      "91 141.89812745341376 907\n",
      "34 145.4874079405312 593\n",
      "12 150.4222884283131 259\n",
      "79 150.96747631570847 121\n",
      "5 153.28525919789095 131\n",
      "77 158.45450950632284 309\n",
      "76 160.3301460312119 412\n",
      "32 160.5522298691583 529\n",
      "86 163.80066232010896 459\n",
      "17 167.96791966496406 469\n",
      "16 169.43091525438913 409\n",
      "84 175.3279067466381 319\n",
      "43 176.55995055296378 671\n",
      "41 186.39457457590618 355\n",
      "40 187.51751572679106 345\n",
      "93 193.27758953732658 96\n",
      "51 195.6463480157849 334\n",
      "25 198.45337804271924 536\n",
      "81 198.78572838178533 342\n",
      "96 199.56468911646033 181\n",
      "101 200.25819917045973 375\n",
      "33 205.63157797659326 332\n",
      "39 224.35195040030584 294\n",
      "90 231.24254034755694 262\n",
      "35 232.46235354572164 442\n",
      "30 236.53252272091416 398\n",
      "8 241.35434448196168 626\n",
      "45 255.87789043334618 312\n",
      "4 283.3907057841118 236\n"
     ]
    }
   ],
   "source": [
    "for _ in sorted(searchResult.items(), key=lambda x:x[1]):\n",
    "    print(_[0], _[1], len(word_tokenize(collection[_[0]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4 tf-idf 를 활용한 유클리드를 활용한 문서 유사도 측정 개선하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"일본의 수출규제 문제를 놓고 일본의 치열한 논리싸움\"\n",
    "query = \"트럼프 문재인 판문점 판문점\"\n",
    "tokens = word_tokenize(query)\n",
    "queryTDM = defaultdict(int)\n",
    "for _ in tokens:\n",
    "    queryTDM[_] += 1\n",
    "queryMax = max(queryTDM.values())\n",
    "\n",
    "a = 0.5\n",
    "queryWeight = defaultdict(float)\n",
    "for t, f in queryTDM.items():\n",
    "    TF = a + (1-a)*(f/queryMax)\n",
    "    \n",
    "    if t in Vocabulary:\n",
    "        queryWeight[t] = TF * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWM = defaultdict(lambda:defaultdict(float))\n",
    "\n",
    "for t, docDict in TDM.items():\n",
    "    for d, f in docDict.items():\n",
    "        TF = f/max(DTM[d].values())\n",
    "        IDF = log2(N/len(docDict))\n",
    "        TWM[t][d] = TF*IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 0.2844781272830869),\n",
       " (36, 0.25349086615432354),\n",
       " (23, 0.15408840507051028),\n",
       " (1, 0.12626411294470039),\n",
       " (53, 0.09371699311651595),\n",
       " (46, 0.08849662123448318),\n",
       " (98, 0.06804853686617969),\n",
       " (50, 0.06791698589412037),\n",
       " (6, 0.06511373117295473),\n",
       " (82, 0.04129095642702978),\n",
       " (66, 0.03927511447621787),\n",
       " (16, 0.03413721084889412),\n",
       " (61, 0.030288109594095235),\n",
       " (9, 0.029790171479342677),\n",
       " (20, 0.029221609519762597),\n",
       " (68, 0.02637656696510156),\n",
       " (3, 0.021415390931196366),\n",
       " (65, 0.021227614257779606),\n",
       " (27, 0.02119880711579494),\n",
       " (40, 0.02044320593860406),\n",
       " (97, 0.00891348696399001)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchResult = defaultdict(float)\n",
    "for t, w1 in queryWeight.items():\n",
    "    for d, w2 in TWM[t].items():\n",
    "        searchResult[d] += w1*w2\n",
    "for d, innerProduct in searchResult.items():\n",
    "    docLength = sqrt(sum([TWM[t][d]**2\n",
    "                          for t in list(DTM[d].keys())]))\n",
    "    searchResult[d] = innerProduct / docLength\n",
    "    \n",
    "sorted(searchResult.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(defaultdict(float,\n",
       "             {1: 0.15587758686770914,\n",
       "              10: 0.272785777018491,\n",
       "              20: 0.198389656013448,\n",
       "              36: 1.1903379360806878,\n",
       "              50: 0.36371436935798795}),\n",
       " defaultdict(float,\n",
       "             {0: 0.0,\n",
       "              1: 0.0,\n",
       "              2: 0.0,\n",
       "              3: 0.0,\n",
       "              4: 0.0,\n",
       "              5: 0.0,\n",
       "              6: 0.0,\n",
       "              7: 0.0,\n",
       "              8: 0.0,\n",
       "              9: 0.0,\n",
       "              10: 0.0,\n",
       "              11: 0.0,\n",
       "              12: 0.0,\n",
       "              13: 0.0,\n",
       "              14: 0.0,\n",
       "              15: 0.0,\n",
       "              16: 0.0,\n",
       "              17: 0.0,\n",
       "              18: 0.0,\n",
       "              19: 0.0,\n",
       "              20: 0.0,\n",
       "              21: 0.0,\n",
       "              22: 0.0,\n",
       "              23: 0.0,\n",
       "              24: 0.0,\n",
       "              25: 0.0,\n",
       "              26: 0.0,\n",
       "              27: 0.0,\n",
       "              28: 0.0,\n",
       "              29: 0.0,\n",
       "              30: 0.0,\n",
       "              31: 0.0,\n",
       "              32: 0.0,\n",
       "              33: 0.0,\n",
       "              34: 0.0,\n",
       "              35: 0.0,\n",
       "              36: 0.0,\n",
       "              37: 0.0,\n",
       "              38: 0.0,\n",
       "              39: 0.0,\n",
       "              40: 0.0,\n",
       "              41: 0.0,\n",
       "              42: 0.0,\n",
       "              43: 0.0,\n",
       "              44: 0.0,\n",
       "              45: 0.0,\n",
       "              46: 0.0,\n",
       "              47: 0.0,\n",
       "              48: 0.0,\n",
       "              49: 0.0,\n",
       "              50: 0.0,\n",
       "              51: 0.0,\n",
       "              52: 0.0,\n",
       "              53: 0.0,\n",
       "              54: 0.0,\n",
       "              55: 0.0,\n",
       "              56: 0.0,\n",
       "              57: 0.0,\n",
       "              58: 0.0,\n",
       "              59: 0.0,\n",
       "              60: 0.0,\n",
       "              61: 0.0,\n",
       "              62: 0.0,\n",
       "              63: 0.0,\n",
       "              64: 0.0,\n",
       "              65: 0.0,\n",
       "              66: 0.0,\n",
       "              67: 0.0,\n",
       "              68: 0.0,\n",
       "              69: 0.0,\n",
       "              70: 0.0,\n",
       "              71: 0.0,\n",
       "              72: 0.0,\n",
       "              73: 0.0,\n",
       "              74: 0.0,\n",
       "              75: 0.0,\n",
       "              76: 0.0,\n",
       "              77: 0.0,\n",
       "              78: 0.0,\n",
       "              79: 0.0,\n",
       "              80: 0.0,\n",
       "              81: 0.0,\n",
       "              82: 0.0,\n",
       "              83: 0.0,\n",
       "              84: 0.0,\n",
       "              85: 0.0,\n",
       "              86: 0.0,\n",
       "              87: 0.0,\n",
       "              88: 0.0,\n",
       "              89: 0.0,\n",
       "              90: 0.0,\n",
       "              91: 0.0,\n",
       "              92: 0.0,\n",
       "              93: 0.0,\n",
       "              94: 0.0,\n",
       "              95: 0.0,\n",
       "              96: 0.0,\n",
       "              97: 0.0,\n",
       "              98: 0.0,\n",
       "              99: 0.0,\n",
       "              100: 0.0,\n",
       "              101: 0.0,\n",
       "              102: 0.0}))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zif's Law 에서 중요도 측정\n",
    "# \"// flash 오류를 우회하기 위한 함수 추가\" 의 '오류','우회','함수' 가중치는 0 변환\n",
    "TWM[\"판문점\"], TWM[\"우회\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'// flash 오류를 우회하기 위한 함수 추가\\nfunction _flash_removeCallback() {}\\n\\n\\t\\n\\t교수는 스스로 7점 만점에 6.3점…학생은 4.3점 줘고혁진 코리아텍 교수 설문조사 결과…연구환경 인식 차이 커\\'불 꺼진 교수실\\'[연합뉴스 자료 사진](대전=연합뉴스) 이재림 기자 = 국내 청년 과학자와 교수 간 연구 환경에 대한 인식차가 적지 않은 것으로 나타났다. 진로에 대한 관심 여부는 그 간극이 크게 벌어져 있는 것으로 파악됐다.    25일 한국연구재단(NRF)에 따르면 고혁진 한국산업기술대학교(코리아텍) 교수를 비롯한 재단 정책혁신팀은 연구환경에 대한 이해당사자 간 인식 차이 조사 심층진단 내용을 \\'NRF 이슈리포트\\'로 발표했다.    4월 17∼25일 이공계 대학원생 및 박사 후 연구원(청년과학자) 3천301명을 상대로, 5월 2∼16일 이공분야 지원사업 수행 교수(연구책임자) 2천488명을 상대로 각각 설문 조사했다.    연구실 문화를 살필 수 있는 문항에 대한 응답 분석 결과 모든 항목에서 교수가 학생보다 긍정적이었다.    교수의 경우는 긍정적 응답 비율이 부정적인 것보다 압도적으로 높았다.    학생 인식 수준을 기준으로 한 인식 수준 표준화 값(교수 인식 수준-학생 인식 수준/학생 인식 수준)을 보면 두 집단의 인식 차이는 24.8% 정도다.    특히 진로에 대한 적극적인 관심에 대한 차이는 46.5%나 됐다.     \\'지도교수는 제자의 진로에 대해 적극적인 관심을 갖고 있다\\'라는 문항에 교수는 6.3점을, 학생은 4.3점(이상 7점 만점)을 각각 매겼다.    이는 지난해 국제 학술지 네이처(nature)가 \\'연구실 리더십 문제\\'(Leadership problem In The Lab)에서 공개한 외국 사례를 크게 웃도는 수치다. 외국에서 연구책임자와 연구원 간 진로 상담 인식 차이는 28%였다.    국내의 경우 동료·선배와의 차별 여부(32.8%)와 과제 참여를 통한 경제적 보상(30.4%)에 대해서도 인식 차이가 컸다.    리포트 집필진은 \"국내·외 사례를 비교했을 때 진로나 경제 문제에 대한 인식 차이가 큰 점은 우리나라 과학계에 시사하는 바가 있다\"며 \"지도교수의 더 깊은 관심과 노력이 필요하다\"고 지적했다.    walden@yna.co.kr▶확 달라진 연합뉴스 웹을 만나보세요▶네이버 [연합뉴스] 채널 구독   ▶뭐 하고 놀까? #흥'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
