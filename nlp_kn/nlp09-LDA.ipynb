{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **자연어 8일 - UnSupervised with NLP**\n",
    "자연어 Token 데이터를 활용한 K-Means 의 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Search Engine Index 복습**\n",
    "1. **DTM (Document Term Matrix) 모델 :** 전체 Token을 확인하여 검색 비용이 높다\n",
    "1. **TDM (Term-Document Matrix) 모델 :** Token 별 **검색 Tree** 를 미리 재구성해 비용이 낮다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = [\n",
    "    [\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
    "    [\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
    "    [\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
    "    [\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
    "    [\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
    "    [\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
    "    [\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
    "    [\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
    "    [\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
    "    [\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
    "    [\"statistics\", \"R\", \"statsmodels\"],\n",
    "    [\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
    "    [\"pandas\", \"R\", \"Python\"],\n",
    "    [\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
    "    [\"libsvm\", \"regression\", \"support vector machines\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed, randrange\n",
    "seed(0)\n",
    "\n",
    "K = 3\n",
    "V = list(set([t for d in collection for t in d]))\n",
    "Z = list(list(randrange(K) for t in d)\n",
    "         for d in collection)\n",
    "Phi = list(list(0 for t in V) for k in range(K))\n",
    "Theta = list(list(0 for k in range(K)) for d in collection)\n",
    "\n",
    "for i, d in enumerate(Z):\n",
    "    for j, topic in enumerate(d):\n",
    "        Phi[topic][V.index(collection[i][j])] += 1\n",
    "        Theta[i][topic] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random, sample, choices\n",
    "\n",
    "def gibbsSampling(i, j):\n",
    "    candidates = list()\n",
    "    for k in range(K):\n",
    "        candidates.append(A(i, j, k) * B(i, k))\n",
    "    \n",
    "    _sum = sum(candidates)\n",
    "    candidates = [_/_sum for _ in candidates]\n",
    "    \n",
    "#     k = choices(list(range(K)), candidates)\n",
    "    \n",
    "    k = 0\n",
    "    threshold = random()\n",
    "    for _k, _ in enumerate(candidates):\n",
    "        threshold -= _\n",
    "        if threshold < 0:\n",
    "            k = _k\n",
    "            break\n",
    "    return k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A(i, j, k):\n",
    "    return (Phi[k][V.index(collection[i][j])] + b)\\\n",
    "            / (sum(Phi[k])+b*len(Phi[k]))\n",
    "\n",
    "def B(i, k):\n",
    "    return (Theta[i][k] + a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.1\n",
    "b = 0.1\n",
    "\n",
    "for _ in range(1000):\n",
    "    for i, d in enumerate(Z):\n",
    "        for j, topic in enumerate(d):\n",
    "            termIdx = V.index(collection[i][j])\n",
    "            Phi[topic][termIdx] -= 1\n",
    "            Theta[i][topic] -= 1\n",
    "            \n",
    "            k = gibbsSampling(i, j)\n",
    "            \n",
    "            Z[i][j] = k\n",
    "            Phi[k][termIdx] += 1\n",
    "            Theta[i][k] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 'regression'), (2, 'scikit-learn'), (2, 'deep learning'), (2, 'artificial intelligence'), (2, 'machine learning')]\n",
      "\n",
      "[(3, 'HBase'), (3, 'Big Data'), (3, 'Java'), (2, 'Hadoop'), (2, 'Cassandra')]\n",
      "\n",
      "[(4, 'R'), (3, 'probability'), (3, 'statistics'), (2, 'statsmodels'), (2, 'pandas')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(K):\n",
    "    print(sorted(list(zip(Phi[k], V)), key=lambda x:x[0],\n",
    "                 reverse=True)[:5])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규식에서 숫자는 : String Range 값을 특정 합니다\n",
    "import os, re\n",
    "fileFolder = \"./News/\" \n",
    "fileList   = [fileFolder + _  for _ in os.listdir(fileFolder) \n",
    "               if re.match(\"\\d{10}.txt\", _) ]\n",
    "\n",
    "# 네이버 뉴스 수집자료를 collection 로 묶는다\n",
    "collection = []\n",
    "for _ in fileList:\n",
    "    with open(_) as f:\n",
    "        collection.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'// flash 오류를 우회하기 위한 함수 추가\\nfunction _flash_removeCallback() {}\\n\\n\\t\\n\\t교수는 스스로 7점 만점에 6.3점…학생은 4.3점 줘고혁진 코리아텍 교수 설문조사 결과…연구환경 인식 차이 커\\'불 꺼진 교수실\\'[연합뉴스 자료 사진](대전=연합뉴스) 이재림 기자 = 국내 청년 과학자와 교수 간 연구 환경에 대한 인식차가 적지 않은 것으로 나타났다. 진로에 대한 관심 여부는 그 간극이 크게 벌어져 있는 것으로 파악됐다.    25일 한국연구재단(NRF)에 따르면 고혁진 한국산업기술대학교(코리아텍) 교수를 비롯한 재단 정책혁신팀은 연구환경에 대한 이해당사자 간 인식 차이 조사 심층진단 내용을 \\'NRF 이슈리포트\\'로 발표했다.    4월 17∼25일 이공계 대학원생 및 박사 후 연구원(청년과학자) 3천301명을 상대로, 5월 2∼16일 이공분야 지원사업 수행 교수(연구책임자) 2천488명을 상대로 각각 설문 조사했다.    연구실 문화를 살필 수 있는 문항에 대한 응답 분석 결과 모든 항목에서 교수가 학생보다 긍정적이었다.    교수의 경우는 긍정적 응답 비율이 부정적인 것보다 압도적으로 높았다.    학생 인식 수준을 기준으로 한 인식 수준 표준화 값(교수 인식 수준-학생 인식 수준/학생 인식 수준)을 보면 두 집단의 인식 차이는 24.8% 정도다.    특히 진로에 대한 적극적인 관심에 대한 차이는 46.5%나 됐다.     \\'지도교수는 제자의 진로에 대해 적극적인 관심을 갖고 있다\\'라는 문항에 교수는 6.3점을, 학생은 4.3점(이상 7점 만점)을 각각 매겼다.    이는 지난해 국제 학술지 네이처(nature)가 \\'연구실 리더십 문제\\'(Leadership problem In The Lab)에서 공개한 외국 사례를 크게 웃도는 수치다. 외국에서 연구책임자와 연구원 간 진로 상담 인식 차이는 28%였다.    국내의 경우 동료·선배와의 차별 여부(32.8%)와 과제 참여를 통한 경제적 보상(30.4%)에 대해서도 인식 차이가 컸다.    리포트 집필진은 \"국내·외 사례를 비교했을 때 진로나 경제 문제에 대한 인식 차이가 큰 점은 우리나라 과학계에 시사하는 바가 있다\"며 \"지도교수의 더 깊은 관심과 노력이 필요하다\"고 지적했다.    walden@yna.co.kr▶확 달라진 연합뉴스 웹을 만나보세요▶네이버 [연합뉴스] 채널 구독   ▶뭐 하고 놀까? #흥'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 오류를 우회하기 위한 함수 추가 그리샴 취임 후 한달새 침묵 미국인 대변인 목소리도 몰라 트럼프 대변인 역할 보좌로 한정스테파니 그리샴 미 백악관 대변인 연합뉴스 서울경제 도널드 트럼프 미국 대통령의 새로운 입 으로 발탁된 스테파니 그리샴 백악관 대변인이 취임 후 거의 한 달이 지나도록 모습을 보이지 않고 있다 최근 트럼프 대통령이 민주당의 유색 여성 의원들을 겨냥해 인종차별적 막말을 퍼부어 미 정가가 발칵 뒤집어졌지만 그리샴은 단 한 차례도 공식 해명조차 내놓지 않았다 일 현지시간 미 정치전문매체 폴리티코 등 현지언론에 따르면 지난달 일 세라 샌더스 전 대변인의 후임으로 임명된 그리샴은 방송출연은 커녕 기자들의 질문에도 답하지 않는 등 언론과의 접촉을 극도로 삼가고 있다 그는 트럼프 대통령이 민주당 소속 유색 여성 초선의원 인방에게 너희 나라로 돌아가라 등 막말을 일주일 넘게 쏟아내는 와중에도 트위터에 트럼프 대통령을 옹호하는 짧은 글 하나를 올린 것 외엔 메시지를 내지 않았다 백악관 대변인의 이 같은 저자세 는 트럼프 대통령과 언론의 불편한 관계가 영향을 미친 것으로 보인다 트럼프 대통령은 뉴욕타임스 워싱턴포스트 등 주류 언론을 매일 가짜 뉴스 라고 공격하며 전쟁을 벌이고 있고 이 때문에 세라 샌더스 전임 백악관 대변인도 언론 정례 브리핑을 중단한 채 기자단과 냉각기를 가졌다 폴리티코는 그러나 트럼프 대통령의 막말로 미 정계가 정치적 스펙트럼을 떠나 비판으로 들끓고 있는데도 미국인 대다수는 그리샴의 목소리조차 알지 못한다면서 이는 백악관 대변인으로는 매우 이례적이라고 지적했다 그리샴 대변인은 일일 업무 대부분을 하급자들에게 맡기고 본인은 과거 멜라니아 여사의 대변인을 맡았을 때처럼 꼭 필요할 때만 전면에 나서겠다는 입장으로 알려졌다 트위터를 통해 직접 중요 내용을 공개하는 소통 방식을 선호하는 트럼프 대통령에게 언론의 관심을 집중시키고 본인은 기자들에게는 대통령과 직접 접촉할 기회를 최대한 많이 만들어주는 일종의 중개인 역할을 하겠다는 것이다 한편 폴리티코는 백악관 내부 인사들은 그런 그리샴 대변인을 한 목소리로 두둔하고 있다고 전했다 여기에는 그리샴 대변인에 대한 트럼프 대통령과 멜라니아 여사의 신뢰가 두텁다는 점과 백악관 내부의 배타적 분위기가 영향을 미쳤을 수 있다 폴리티코는 친정부 성향 매체인 폭스뉴스 출신 인사 등이 발탁될 것을 우려했던 백악관과 정부 고위 인사들이 내부 인사인 그리샴이 백악관 대변인과 공보국장을 맡는 것을 크게 환영했다고 전했다 트럼프 대통령의 큰딸 이방카와 사위 재러드 쿠슈너 백악관 선임 보좌관도 그리샴의 팬으로 알려졌다 그리샴 대변인은 년 대선 초창기부터 트럼프 대통령을 위해 일했다 퍼스트레이디 업무를 관장하는 백악관 이스트 윙 동관 대변인으로 있을 때도 주로 막후에 머물렀다 하지만 그리샴 대변인은 이런 대외적 모습과는 달리 아침 일찍부터 종일 트럼프 대통령과 연락을 주고받고 대면 보고를 하는 등 바쁜 일정을 소화하고 있다 취임 직후에는 지난달 말 일본 오사카에서 열린 주요 개국 정상회의에서 트럼프 대통령을 수행했고 트럼프 대통령이 판문점에서 김정은 북한 국무위원장과 회동했을 때는 미국 공동취재단을 제지하는 북측 경호원들에 맞서 몸싸움을 벌이기도 했다 당시 그는 북측 경호원들을 옆으로 밀어내 통로를 확보하고 미국 기자들에게 가요 가 라고 말했고 이 과정에서 몸에 멍이 드는 등 가벼운 상처를 입었다 백악관 출입기자단 간사인 조너선 칼은 백악관 공동기자단이 접근할 수 있도록 문자 그대로 투쟁했던 것은 좋은 시작이었다 고 말했다 박민주기자 서울경제 바로가기 텔레그램으로 서울경제 구독하기 네이버 로 서울경제썸 구독하기 네이버 메인에서 뉴스 서울경제를 만나보세요저작권자 서울경제 무단 전재 및 재배포 금지'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전처리\n",
    "import re\n",
    "from string import punctuation\n",
    "pattern1 = re.compile(r\"[{0}]\".format(re.escape(punctuation)))\n",
    "\n",
    "# 5글자 이상의 영어\n",
    "pattern2 = re.compile(r\"[A-z]{5,}\")\n",
    "pattern3 = re.compile(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣]\")\n",
    "# 하이퍼스페이스 2개 이상일 때\n",
    "pattern4 = re.compile(r\"\\s{2,}\")\n",
    "\n",
    "for i, d in enumerate(collection):\n",
    "    collection[i] = \\\n",
    "        pattern4.sub(\" \", pattern3.sub(\" \", pattern2.sub(\" \", pattern1.sub(\" \", d))))\n",
    "\n",
    "collection[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "ne = Mecab().nouns\n",
    "V = []\n",
    "for i, d in enumerate(collection):\n",
    "    collection[i] = [noun for noun in ne(d)  if len(noun) > 1]\n",
    "    V.extend(collection[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = list(set(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['낙원',\n",
       " '추구',\n",
       " '횟집',\n",
       " '복지',\n",
       " '타스',\n",
       " '자행',\n",
       " '탐지',\n",
       " '레버리지',\n",
       " '어려움',\n",
       " '특허',\n",
       " '후임자',\n",
       " '심리',\n",
       " '방통',\n",
       " '인터내셔널',\n",
       " '지체',\n",
       " '담화',\n",
       " '압력',\n",
       " '화물기',\n",
       " '상체']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V[:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed, randrange\n",
    "seed(0)\n",
    "\n",
    "K = 20\n",
    "V = list(set([t for d in collection for t in d]))\n",
    "Z = list(list(randrange(K) for t in d)\n",
    "         for d in collection)\n",
    "Phi = list(list(0 for t in V) for k in range(K))\n",
    "Theta = list(list(0 for k in range(K)) for d in collection)\n",
    "Phisum = list(0 for k in range(K))\n",
    "\n",
    "for i, d in enumerate(Z):\n",
    "    for j, topic in enumerate(d):\n",
    "        Phi[topic][V.index(collection[i][j])] += 1\n",
    "        Theta[i][topic] += 1\n",
    "        Phisum[topic] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random, sample, choices\n",
    "\n",
    "def gibbsSampling(i, j):\n",
    "    candidates = list()\n",
    "    for k in range(K):\n",
    "        candidates.append(A(i, j, k) * B(i, k))\n",
    "    \n",
    "    _sum = sum(candidates)\n",
    "    candidates = [_/_sum for _ in candidates]\n",
    "    \n",
    "#     k = choices(list(range(K)), candidates)\n",
    "    \n",
    "    k = 0\n",
    "    threshold = random()\n",
    "    for _k, _ in enumerate(candidates):\n",
    "        threshold -= _\n",
    "        if threshold < 0:\n",
    "            k = _k\n",
    "            break\n",
    "    return k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(V)\n",
    "\n",
    "def A(i, j, k):\n",
    "    return (Phi[k][V.index(collection[i][j])] + b)\\\n",
    "            / (Phisum[k] + b*N) #len(Phi[k]))\n",
    "\n",
    "def B(i, k):\n",
    "    return (Theta[i][k] + a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.1\n",
    "b = 0.1\n",
    "\n",
    "for _ in range(10):\n",
    "    for i, d in enumerate(Z):\n",
    "        for j, topic in enumerate(d):\n",
    "            termIdx = V.index(collection[i][j])\n",
    "            Phi[topic][termIdx] -= 1\n",
    "            Theta[i][topic] -= 1\n",
    "            Phisum[topic] -= 1\n",
    "            \n",
    "            k = gibbsSampling(i, j)\n",
    "            \n",
    "            Z[i][j] = k\n",
    "            Phi[k][termIdx] += 1\n",
    "            Theta[i][k] += 1\n",
    "            Phisum[topic] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, '대법관'), (1, '윤석열'), (1, '이정아'), (0, '낙원'), (0, '추구'), (0, '횟집'), (0, '복지'), (0, '타스'), (0, '자행'), (0, '탐지')]\n",
      "[(11, '보예'), (11, '보디'), (8, '국왕'), (7, '말레이시아'), (6, '황병승'), (4, '결혼'), (4, '일본군'), (4, '무하'), (3, '성희롱'), (3, '스타')]\n",
      "[(25, '리콜'), (20, '기아차'), (17, '현대차'), (16, '결함'), (15, '편의점'), (15, '주차'), (10, '관리법'), (10, '세타'), (10, '파업'), (10, '쓰촨')]\n",
      "[(107, '일본'), (24, '안보'), (23, '이순신'), (19, '임상훈'), (15, '캐치'), (14, '치매'), (13, '정걸'), (13, '양국'), (13, '해협'), (13, '장군')]\n",
      "[(1, '지난주'), (1, '일지'), (0, '낙원'), (0, '추구'), (0, '횟집'), (0, '복지'), (0, '타스'), (0, '자행'), (0, '탐지'), (0, '레버리지')]\n",
      "[(1, '외교관'), (0, '낙원'), (0, '추구'), (0, '횟집'), (0, '복지'), (0, '타스'), (0, '자행'), (0, '탐지'), (0, '레버리지'), (0, '어려움')]\n",
      "[(248, '한국'), (213, '러시아'), (196, '기자'), (193, '일본'), (162, '정부'), (153, '미국'), (132, '북한'), (126, '추가'), (119, '뉴스'), (116, '네이버')]\n",
      "[(4, '독립군'), (2, '카자흐스탄'), (1, '신원'), (1, '작가'), (1, '물질'), (1, '호기'), (1, '성기'), (0, '낙원'), (0, '추구'), (0, '횟집')]\n",
      "[(1, '가로수길'), (1, '유리창'), (0, '낙원'), (0, '추구'), (0, '횟집'), (0, '복지'), (0, '타스'), (0, '자행'), (0, '탐지'), (0, '레버리지')]\n",
      "[(1, '시사점'), (0, '낙원'), (0, '추구'), (0, '횟집'), (0, '복지'), (0, '타스'), (0, '자행'), (0, '탐지'), (0, '레버리지'), (0, '어려움')]\n",
      "[(1, '공표'), (1, '서울경제'), (0, '낙원'), (0, '추구'), (0, '횟집'), (0, '복지'), (0, '타스'), (0, '자행'), (0, '탐지'), (0, '레버리지')]\n",
      "[(1, '통지'), (0, '낙원'), (0, '추구'), (0, '횟집'), (0, '복지'), (0, '타스'), (0, '자행'), (0, '탐지'), (0, '레버리지'), (0, '어려움')]\n",
      "[(73, '간염'), (15, '바이러스'), (13, '치료제'), (10, '접종'), (7, '치료'), (6, '간암'), (6, '백신'), (5, '환자'), (4, '내과'), (4, '간경변증')]\n",
      "[(32, '비행'), (27, '무관'), (13, '조종사'), (9, '스가'), (9, '카카오'), (8, '와인'), (7, '폭격기'), (7, '규정'), (7, '침범'), (7, '부인')]\n",
      "[(1, '치사'), (0, '낙원'), (0, '추구'), (0, '횟집'), (0, '복지'), (0, '타스'), (0, '자행'), (0, '탐지'), (0, '레버리지'), (0, '어려움')]\n",
      "[(38, '경찰'), (20, '할머니'), (17, '불매'), (14, '고유'), (12, '매물'), (12, '김복동'), (12, '감독'), (10, '게임즈'), (10, '경찰서'), (9, '쓰레기')]\n",
      "[(11, '명구'), (5, '직무'), (2, '교단'), (1, '분업'), (1, '각료'), (1, '소지'), (1, '기독교'), (0, '낙원'), (0, '추구'), (0, '횟집')]\n",
      "[(0, '낙원'), (0, '추구'), (0, '횟집'), (0, '복지'), (0, '타스'), (0, '자행'), (0, '탐지'), (0, '레버리지'), (0, '어려움'), (0, '특허')]\n",
      "[(6, '콘크리트'), (5, '한빛'), (4, '원자로'), (4, '방사능'), (4, '건설'), (2, '김애린'), (1, '가동'), (1, '격납'), (1, '교단'), (1, '구멍')]\n",
      "[(0, '낙원'), (0, '추구'), (0, '횟집'), (0, '복지'), (0, '타스'), (0, '자행'), (0, '탐지'), (0, '레버리지'), (0, '어려움'), (0, '특허')]\n"
     ]
    }
   ],
   "source": [
    "# i번쨰 문서의 j번쨰 단어의 Topic 이 K 일때\n",
    "# Perplexity\n",
    "# P(토픽비율) = Theta[i][k] / sum(Theta[i])\n",
    "# P(단어비율) = Phi[k][j=v] / sum(Phi[k])\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "font = \"/home/markbaum/.local/share/fonts/D2Coding.ttf\"\n",
    "wc   = WordCloud(font_path=font, # max_words=10,\n",
    "                 background_color=\"white\")\n",
    "\n",
    "for k in range(K):\n",
    "    print(sorted(list(zip(Phi[k], V)), key=lambda x:x[0], reverse=True)[:10])\n",
    "#     temp = sorted(list(zip(Phi[k], V)), key=lambda x:x[0], reverse=True)[:10]\n",
    "#     wc.generate_from_frequencies({_[1]:_[0]  for _ in temp})    \n",
    "#     plt.imshow(wc.to_array())\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, d.index(max(d)))  for i, d  in enumerateerate(Theta)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, '대법관'),\n",
       " (1, '윤석열'),\n",
       " (1, '이정아'),\n",
       " (0, '낙원'),\n",
       " (0, '추구'),\n",
       " (0, '횟집'),\n",
       " (0, '복지'),\n",
       " (0, '타스'),\n",
       " (0, '자행'),\n",
       " (0, '탐지')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSA : 동일한 성능에 동일한 결과를 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVD : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Top K\n",
    "1. Instance Based Learning\n",
    "1. 학습의 과정이 미리 있어야 한다 (추가/ 삭제 과정이 가능)\n",
    "1. 경계면, 오류로 분류가 다르게 나온경우 분류 방식으로 대안으로 적용가능\n",
    "\n",
    "\n",
    "KNN : True 벨류가 있다 (지도학습)\n",
    "    주변의 K개의 이웃이 있을때 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 감성분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PMI   NPMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focus Based Supervised Learning\n",
    "1. 특정한 Seed Word 를 사용하여 긍부정을 판단할 수 있다\n",
    "1. Corpus 와 Dictionary 를 바탕으로 감성분석을 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web 분석은 실시간성을 반영해, 각종 지표들의 선행지표로써 추정하는 모델링 방법들이 연구"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter Sentiment\n",
    "1. 개별 이벤트별로 Sentiment 분석결과를 Dash Board 로 제공\n",
    "1. 맞는 부분을 추려서 쓸만한 부분들을 연구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
