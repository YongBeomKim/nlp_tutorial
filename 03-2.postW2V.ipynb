{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Word2Vec 분석하기**\n",
    "1. **Frequency 분석** ( **문서의 개요** 살펴보기)\n",
    "1. **Tf IDF** 분석 ( **특정 모집단 내 일부 문서의 특징** 찾기)\n",
    "1. **Word2Vec 모델의** 분석 ( **적은 데이터로 키워드** 특징찾기)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1 PreProcessing 2 유효문장 선별하기**\n",
    "**Word2vec** 을 만들기 위해서는 **문장 데이터로** 전처리가 필요하다\n",
    "1. **그냥 만든경우** 와, **문장을 선별한 경우를** 비교하여 성능 향상 시키기\n",
    "1. **핵심 Token 을 찾고**, 이를 바탕으로 word2vec 결과값 필터링 하기 **(Core 찾기가 우선)**\n",
    "1. 여기선 **문장내 단어가 3개 이상 출연한** 문장만 선별하기\n",
    "\n",
    "```\n",
    "'NNB': '의존 명사',\n",
    "'NNBC': '단위를 나타내는 명사',\n",
    "'NNG': '일반 명사',\n",
    "'NNP': '고유 명사',\n",
    "'NP': '대명사',\n",
    "'VA': '형용사',\n",
    "'VV': '동사',\n",
    "'XSA': '형용사 파생 접미사',\n",
    "'XSN': '명사파생 접미사',\n",
    "'XSV': '동사 파생 접미사'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>가슴살_계란_닭_장조림</td>\n",
       "      <td>반찬 볶음 조림\\n부드러운 닭가슴살 장조림 만들기\\n베리츄\\n\\n2017.9\\n1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>가슴살_굴소스_닭_볶음밥</td>\n",
       "      <td>아임닭 7기 종료\\n수비드 닭가슴살 요리 돈까스 볶음밥 만들기\\n주니호맘\\n\\n20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>가슴살_닭_라이스_카레</td>\n",
       "      <td>food\\n닭의품격 초간편 냉동닭가슴살 카레라이스 만들기\\n유누네\\n\\n2018.9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Query                                              Posts\n",
       "0   가슴살_계란_닭_장조림  반찬 볶음 조림\\n부드러운 닭가슴살 장조림 만들기\\n베리츄\\n\\n2017.9\\n1....\n",
       "1  가슴살_굴소스_닭_볶음밥  아임닭 7기 종료\\n수비드 닭가슴살 요리 돈까스 볶음밥 만들기\\n주니호맘\\n\\n20...\n",
       "2   가슴살_닭_라이스_카레  food\\n닭의품격 초간편 냉동닭가슴살 카레라이스 만들기\\n유누네\\n\\n2018.9..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "df        = pd.read_csv(\"data/naverPost_muyong.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 176.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반찬 볶음 조림\n",
      "부드러운 닭가슴살 장조림 만들기\n",
      "본문 기타 기능\n",
      "조림 밑반찬으로 대표적인 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>가슴살_계란_닭_장조림</td>\n",
       "      <td>반찬 볶음 조림\\n부드러운 닭가슴살 장조림 만들기\\n베리츄\\n\\n2017.9\\n1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>가슴살_굴소스_닭_볶음밥</td>\n",
       "      <td>아임닭 7기 종료\\n수비드 닭가슴살 요리 돈까스 볶음밥 만들기\\n주니호맘\\n\\n20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Query                                              Posts\n",
       "0   가슴살_계란_닭_장조림  반찬 볶음 조림\\n부드러운 닭가슴살 장조림 만들기\\n베리츄\\n\\n2017.9\\n1....\n",
       "1  가슴살_굴소스_닭_볶음밥  아임닭 7기 종료\\n수비드 닭가슴살 요리 돈까스 볶음밥 만들기\\n주니호맘\\n\\n20..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_posts = df.Posts.tolist()\n",
    "result    = []\n",
    "\n",
    "for posts in tqdm(key_posts[:3]):\n",
    "    posts_temp = []\n",
    "    for post in posts.split(\"|\"): # 500 개 문장\n",
    "        for _ in post.split(\"\\n\"):\n",
    "            if len(_.split(\" \")) >= 3: # 3단어 이상으로 구성된 문장만\n",
    "                posts_temp.append(_.strip())\n",
    "    result.append(\"\\n\".join(posts_temp))\n",
    "# print(result[0][:50])\n",
    "# df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Token: 가슴살   Count: 17\n",
      "Key Token: 계란    Count: 110\n",
      "Key Token: 닭     Count: 33\n",
      "Key Token: 장조림   Count: 377\n"
     ]
    }
   ],
   "source": [
    "# Posts 0번 키워드가 본문에 몇번 출현했는지 확인\n",
    "post_temp = []\n",
    "for _ in df.Posts[0].splitlines():\n",
    "    post_temp.extend(_.split(\" \"))\n",
    "\n",
    "# Query 내용 살펴보기\n",
    "from collections import Counter\n",
    "for _ in df.Query[0].split(\"_\"):\n",
    "    print(\"Key Token: {:4}  Count: {}\".format(_.strip(), Counter(post_temp)[_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('짜장면', 'Noun'),\n",
       " ('부대찌개', 'Noun'),\n",
       " ('탕수육', 'Noun'),\n",
       " ('맛있다', 'Adjective'),\n",
       " ('시원하다', 'Adjective'),\n",
       " ('짜다', 'Verb'),\n",
       " ('조르다', 'Verb')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Okt().pos(\"짜장면 부대찌개 탕수육 맛있게 시원하게 짭조름하다\", stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('짜장면', 'NNG'),\n",
       " ('부대찌개', 'NNG'),\n",
       " ('탕수육', 'NNG'),\n",
       " ('맛있', 'VA'),\n",
       " ('게', 'EC'),\n",
       " ('시원', 'XR'),\n",
       " ('하', 'XSA'),\n",
       " ('게', 'EC'),\n",
       " ('짭조름', 'XR'),\n",
       " ('하', 'XSA'),\n",
       " ('다', 'EC')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mecab().pos(\"짜장면 부대찌개 탕수육 맛있게 시원하게 짭조름하다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EC // EF // EP // ETM // ETN // IC // JC // JKB // JKC // JKG // JKO // JKQ // JKS // JKV // JX // MAG // MAJ // MM // NNB // NNBC // NNG // NNP // NP // NR // SC // SE // SF // SH // SL // SN // SSC // SSO // SY // VA // VCN // VCP // VV // VX // XPN // XR // XSA // XSN // XSV'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" // \".join(list(Mecab().tagset.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adjective // Adverb // Alpha // Conjunction // Determiner // Eomi // Exclamation // Foreign // Hashtag // Josa // KoreanParticle // Noun // Number // PreEomi // Punctuation // ScreenName // Suffix // Unknown // Verb'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" // \".join(list(Okt().tagset.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'가감/ 가게/ 가격/ 가공/ 가기/ 가까이/ 가깝다/ 가꾸다/ 가끔/ 가능/ 가능하다/ 가다/ 가도/ 가두다/ 가득/ 가득하다/ 가랑이/ 가량/ 가로/ 가루/ 가르다/ 가리비/ 가만히/ 가면/ 가미/ 가버리다/ 가벼워지다/ 가볍다/ 가성/ 가세/ 가스/ 가스레인지/ 가슴/ 가시다/ 가쓰오부시/ 가씨/ 가야/ 가열/ 가오/ 가요/ 가운데/ 가위/ 가을/ 가입/ 가장/ 가장자리/ 가정/ 가정식/ 가족/ 가족사진/ 가지/ 가지다/ 가지런하다/ 각/ 각각/ 각종/ 간/ 간간/ 간간히/ 간과/ 간다/ 간단/ 간단하다/ 간도/ 간만/ 간식/ 간의/ 간이/ 간장/ 간장게장/ 간편하다/ 간혹/ 갈고/ 갈기갈기/ 갈다/ 갈라/ 갈릭/ 갈비/ 갈색/ 갈아/ 갈치/ 감/ 감기/ 감다/ 감사하다/ 감싸다/ 감안/ 감염/ 감자/ 감칠맛/ 감탄/ 갑/ 갑자기/ 값/ 갓/ 강/ 강된장/ 강렬하다/ 강불/ 강원/ 강중/ 강추/ 강하다/ 강화유리/ 갖다/ 갖은/ 갖추다/ 같다/ 같이/ 개/ 개그맨/ 개다/ 개도/ 개똥/ 개르/ 개봉/ 개운하다/ 개월/ 개월땐/ 개인/ 개정/ 개취/ 개폐/ 갯수/ 걍/ 거/ 거기/ 거나/ 거들다/ 거랍니/ 거르기/ 거른/ 거름/ 거리/ 거릴정도/ 거무틱틱/'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Mecab, Okt\n",
    "df.Posts[0][:100]\n",
    "tokens = [_[0]  for _ in Okt().pos(df.Posts[0], stem=True)\n",
    "                if _[1] in ['Adverb','Verb','Noun','Adjective']]\n",
    "\"/ \".join(sorted(list(set(tokens))))[:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'풀어놓 // 날아가 // 지키 // 절묘 // 아프 // 뜨거우 // 캐 // 무섭 // 유명 // 진하 // 쓰이 // 근사 // 부대끼 // 무 // 은은 // 후덥지근 // 돌려먹 // 높 // 꼼꼼 // 나가 // 말캉 // 오르 // 만드 // 한가 // 넘어가 // 연하 // 잽싸 // 꺼림 // 묻 // 삶 // 짭조름 // 이렇 // 못지않 // 기 // 차갑 // 녹 // 채우 // 찢어지 // 먹히 // 퍼지 // 기다리 // 부드럽 // 하얗 // 들 // 걷어가 // 배어드 // 배 // 잠기 // 따 // 눌'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Mecab, Okt\n",
    "df.Posts[0][:100]\n",
    "tokens = [_[0]  for _ in Mecab().pos(df.Posts[0]) \n",
    "       if _[1] in ['XR','VA','VV']]\n",
    "\" // \".join(list(set(tokens)))[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어의 전처리 작업 진행하기\n",
    "# ['NNB','NNBC','NNG','NNP','NP','VA','VV','XR','XSA','XSN','XSV']\n",
    "# \n",
    "from konlpy.tag import Mecab, Okt\n",
    "df.Posts[0][:100]\n",
    "tokens = [_[0]  for _ in Mecab().pos(df.Posts[0]) \n",
    "       if _[1] in ['XR','VA','VV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['EC', 'EF', 'EP', 'ETM', 'ETN', 'IC', 'JC', 'JKB', 'JKC', 'JKG', 'JKO', 'JKQ', 'JKS', 'JKV', 'JX', 'MAG', 'MAJ', 'MM', 'NNB', 'NNBC', 'NNG', 'NNP', 'NP', 'NR', 'SC', 'SE', 'SF', 'SH', 'SL', 'SN', 'SSC', 'SSO', 'SY', 'VA', 'VCN', 'VCP', 'VV', 'VX', 'XPN', 'XR', 'XSA', 'XSN', 'XSV'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mecab().tagset.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2 Word2Vec from String**\n",
    "**[Gensim Tutorial](https://radimrehurek.com/gensim/models/word2vec.html)**, ||| **[w2v from Sentence block](https://codesachin.wordpress.com/2015/10/09/generating-a-word2vec-model-from-a-block-of-text-using-gensim-python/)**  \n",
    "1. fasttext 및 gensim 에서는 다음과 같이 파일로 저장한 뒤 활용을 합니다.\n",
    "1. 임시파일을 계속 만들고 저장하는 작업을 줄이기 위해선 별도의 접근방법이 필요합니다.\n",
    "\n",
    "```python\n",
    "%%time\n",
    "from gensim.models import word2vec\n",
    "txt_file = 'w2v_script.txt'\n",
    "data  = word2vec.LineSentence(txt_file)\n",
    "model = word2vec.Word2Vec(data, size=30, window=2, min_count=16, \n",
    "                          hs=1, workers=4, iter=100, sg=1)\n",
    "model.save(model_file)\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> from gensim.models import Word2Vec\n",
    ">>> sentences = [[\"cat\", \"say\", \"meow\"], [\"dog\", \"say\", \"woof\"]]\n",
    ">>>\n",
    ">>> model = Word2Vec(min_count=1)\n",
    ">>> model.build_vocab(sentences)  # prepare the model vocabulary\n",
    ">>> model.train(sentences, total_examples=model.corpus_count, epochs=model.iter)  # train word vectors\n",
    "(1, 30)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.Posts[0].splitlines()[:5]\n",
    "# result[0].splitlines()[:3]\n",
    "# w2v_sentences = [_.split(\" \") for _ in result[0].splitlines()]\n",
    "\n",
    "w2v_sentences = []\n",
    "for _ in df.Posts[0].splitlines():\n",
    "    tokens = Okt().pos(_, stem=True)\n",
    "    tokens = [t[0] for t in tokens  if t[1] in ['Adverb','Verb','Noun','Adjective']]\n",
    "    if len(tokens) > 3:  # 갯수가 3개 이상있는 자료만 추출\n",
    "        w2v_sentences.append(tokens)\n",
    "        \n",
    "# result[0].splitlines()[:3]\n",
    "# w2v_sentences = [_.split(\" \") for _ in result[0].splitlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/momukji/Python/python/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(106980, 171340)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defined Model\n",
    "from gensim.models import Word2Vec\n",
    "w2v_model  = Word2Vec(sg=1, hs=1, workers=4, size=100, min_count=5, window=2)\n",
    "w2v_string = w2v_model.build_vocab(w2v_sentences)\n",
    "w2v_model.train(w2v_sentences, total_examples=w2v_model.corpus_count, epochs=w2v_model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'가감 가격 가끔 가능 가능하다 가다 가득 가량 가루 가슴 가운데 가장 가족 가지 간 간간 간단 간단하다 간만 간이 간장 간편하다 갈다 갈릭 갈색 감기 감다 감자 감칠맛 강하다 같다 같이 개 개월 개인 개정 걍 거 거기 거나 거들다 거의 거품 걱정 건 건강 건강하다 건지다 걷다 걸 걸다 걸리다 것 겉 게 겨울 결 경우 계란 계란말이 계량 계속 계시다 고기 고르다 고민 고소하다 고추 고추가 고추장 곤약 골고루 곳 공감 공기 과 과정 괜찮다 구 구매 구멍 구쁘 구입 국 국물 국자 굳다 굽 굽다 귀찮다 그 그것 그냥 그대로 그동안 그래도 그래서 그렇게 그렇다 그릇 근데 글 금방 급하다 기다 기도 기름 기름기 기분 기억 기한 기호 김 김치 김치볶음밥 깍 깔끔하다 깔다 깨 깨끗이 깨끗하다 깨다 깨지다 꺼내다 껍질 꼬동 꼭 꼭지 꽈리 꽤 꿀 끄다 끓다 끓이다 끝 끼 나 나가다 나다 나머지 나물 나서다 나오다 나중 난 날 날씨 남기다 남다 남편 낮추다 낳다 내 내다 내용 내일 내주다 냄비 냄새 냉동 냉장 냉장고 너무 넉넉하다 넘다 넘치다 넣기 넣다 네이버 노른자 놀다 높다 놓다 누르다 눈 느끼다 느낌 늘 늘다 다 다가 다르다 다른 다시 다시마 다양하다 다음 다이어트 다지다 다해 단 단단하다 단맛 단백질 단호박 닫다 달 달걀 달다 달달 닭 닭고기 담 담그다 담다 담백하다 당근 대다 대략 대신 대체 대충 대파 대하 대한 댓글 더 더욱 더하다 덜 덜다 덥다 덩어리 덩이 덮다 데 데친 도 도둑 도록 도시락 도전 돌다 돌리다 동생 동안 동원 돼다 돼지고기 되다 되어다 두다 두르다 두부 뒤 드디어 드리다 든든하다 들다 들어가다 들어주다 듬뿍 듯 등 등등 따다 따뜻하다 따라서 따로 따르다 딱 때 때문 땐 땡초 떨어지다 떼다 또 또는 또한 뚜껑 뚝딱 뜨겁다 뜨다 뜯다 라면 라이스 란 랍니 래야 레시피 로 로그아웃 로만 를 리 리릭 리뷰 마늘 마르다 마무리 마약 마음 마지막 마트 막 만 만나다 만두 만들기 만들다 만들어지다 만만하다 만큼 만하 많다 많이 말 말다 말리다 맘 맛 맛술 맛있다 맞다 맞추다 매력 매번 매실 매일 매콤 맨 맵 맵다 먹기 먹다 먹음 먹이다 먼저 메뉴 메추리 며칠 멸치 명시 몇 몇개 모두 모든 모르다 모바일 모습 모양 몰다 몸 못 무 문제 물 물기 물다 물론 물엿 물이 뭐 뭔가 뭘 미니 미리 미림 밀가루 밀폐 밉다 밑 밑반찬 바 바닥 바라다 바람 바로 바쁘다 밖 반 반숙 반죽 반찬 받다 밤 밥 밥상 밥위 방법 배 배다 배송 버리다 버섯 버전 버터 번 번거롭다 법 벗겨지다 벗기다 베 베다 베이 베카 변경 변하다 별로 보 보고 보관 보글보글 보기 보내다 보다 보아 보이 보이다 보통 볶다 볶음 볶음밥 볼 봄 봉지 부다 부담 부드럽다 부분 부어 부엌 부위 분 분량 불 불가 불다 불량 불로 붓다 붙다 브로콜리 블로거 블로그 비 비교 비다 비리다 비비다 비슷하다 비싸다 비우다 비율 비타민 빠르다 빠지다 빨리 빼다 뿌리 뿌리다 뿐 사 사과 사다 사람 사실 사오다 사용 사이 사진 살 살다 살로 살의 살이 살짝 살캔 삶 삶다 삼각김밥 삼삼하다 상 상태 새롭다 새벽 새우 색 색깔 색도 샐러드 생 생각 생각나다 생강 생기다 생닭 생략 서서히 섞다 설탕 성분 세 세기 세다 소개 소고기 소금 소스 소주 속 손 손질 솔솔 송송 송이버섯 쇠고기 쇼핑몰 수 수가 수분 수비드 수용 수제비 숙성 숟가락 술 술안주 쉬다 쉽다 스럽다 스며들다 스테이크 스푼 슬 시 시간 시럽 시작 시키다 식 식감 식다 식단 식사 식초 식히다 신경 신랑 신선하다 실 실리콘 싫다 싫어하다 심심하다 싱겁다 싶다 싸다 쌈 써다 썰다 쏙 쏙쏙 쓰다 씹다 씻다 아가 아기 아깝다 아니다 아들 아보카도 아이 아임웰 아주 아직 아직도 아침 안 안되다 안심 않다 알 알다 알도 알림 앞 애정 앱 야채 야하다 약 약간 얇다 양 양념 양념장 양배추 양조 양파 어 어떻다 어렵다 어른 어리다 어울리다 어제 언니 언제 얹다 얻다 얼마 얼마나 엄마 엄청 업데이트 없다 없애다 없어지다 없이 에델코첸 여기 여름 역시 연휴 열다 열심히 염 영리 영양 예쁘다 예정 오늘 오니기리 오다 오래 오래되다 오르다 오븐 오야 오야코동 올라오다 올려주다 올리고당 올리다 완성 완숙 완전 완전하다 왜 요 요건 요렇게 요리 요즘 용 용기 우리 우선 우유 울다 원래 원하다 월계수 위 위해 유정 유지 유통 육수 윤기 으 은 은근 은수 은은하다 음식 의 이 이건 이기 이다 이렇게 이렇다 이르다 이면 이미 이번 이쁘다 이상 이야기 이용 이웃 이유 이제 익 익다 익히다 인터넷 일 일단 일반 일주일 임닭 입 입맛 입히다 있다 잎 자 자꾸 자다 자르다 자연 자작하다 자주 자취 작다 작성 잠기다 잠시 잡곡 잡다 장 장아찌 장조림 재료 재미 재우다 저 저녁 저렴하다 저작자 저희 적다 적당하다 전 전송 전자레인지 절반 점 점점 젓가락 정도 정리 정말 제 제거 제대로 제일 제주 제품 젤 조각 조금 조금씩 조려 조르다 조리 조림 조심하다 조절 조청 졸 졸이다 좀 종류 종이컵 종종 좋다 좋아지다 좋아하다 주 주다 주로 주말 주문 주방 주부 주시 주어 주의 죽다 준 준비 줄 줄다 줄어들다 줄이다 줌 줍다 중 중간 중불 중요하다 즐겁다 즐기다 증발 지금 지나다 지난번 지다 지방 지원 직 진 진짜 진하다 질 짐 집 집다 짜다 짜지다 짧다 짭쪼름 쪽 쪽쪽 쫄깃 쭉쭉 쯤 찌다 찌르다 찍다 찜 찢다 차 차갑다 차다 차려 차이 찬물 참고 참기름 채 채소 챙기다 처음 청 청량고추 청양고추 청주 체 초 촉촉하다 최고 최신 추가 추천 충분하다 취향 치다 친정 카레 칼로리 칼제비 칼집 칼칼하다 캔 커피 컵 코 쿠폰 큐브 크기 크다 클릭 키우다 타다 터 터지다 톨 통 통깨 통조림 통후추 투하 특유 특히 틀 틀다 티스푼 파 파일 파티웍 판 판매 팔팔 팝업창 팩 팬 퍽퍽 편 편리하다 편수웍 편이 편하다 평소 포스팅 포장 포크 퐁당 표고버섯 푸다 푹 풀다 풍부하다 플레이 피망 필수 필요 필요없다 필요하다 하나 하니 하다 하루 하얗다 한번 한쪽 한참 할인 함 함께 항 항상 해 해도 해동 해먹 해보다 해주다 해주시 향 허브 현미 혹시 혹은 혼자 홍 확인 활용 황금 효과 후 후다닥 후라이팬 후추 후춧가루 훈제 훨씬 휘 흐르다 흑설탕 흔들다 흰자 히 힘 힘들다'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(sorted(w2v_model.wv.vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('살다', 0.9665916562080383),\n",
       " ('만들기', 0.9546926021575928),\n",
       " ('요리', 0.9442335963249207),\n",
       " ('통조림', 0.9365988969802856),\n",
       " ('밑반찬', 0.9272643327713013),\n",
       " ('닭고기', 0.9268741607666016),\n",
       " ('이용', 0.9266475439071655),\n",
       " ('살로', 0.9259218573570251),\n",
       " ('만들다', 0.9172545075416565),\n",
       " ('법', 0.9092066287994385),\n",
       " ('살이', 0.9082906246185303),\n",
       " ('완성', 0.9069112539291382),\n",
       " ('동원', 0.8983728885650635),\n",
       " ('다음', 0.8975261449813843),\n",
       " ('달걀', 0.886329174041748),\n",
       " ('팩', 0.8819456696510315),\n",
       " ('굽', 0.8804188966751099),\n",
       " ('수비드', 0.8714650869369507),\n",
       " ('찢다', 0.8665907979011536),\n",
       " ('훈제', 0.8614259362220764)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar([\"가슴\",\"살\", \"계란\", \"닭\", \"장조림\"], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-2c7b24fa57b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "test.python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('앱', 0.4227365553379059),\n",
       " ('업데이트', 0.39159780740737915),\n",
       " ('최신', 0.38090571761131287),\n",
       " ('알림', 0.3807673454284668),\n",
       " ('버전', 0.3771092891693115),\n",
       " ('올리고당', 0.3755277097225189),\n",
       " ('거나', 0.3750928044319153),\n",
       " ('설탕', 0.37458086013793945),\n",
       " ('술', 0.36780059337615967),\n",
       " ('전송', 0.3664911091327667),\n",
       " ('네이버', 0.362702876329422),\n",
       " ('물엿', 0.331267774105072),\n",
       " ('월계수', 0.324979305267334),\n",
       " ('컵', 0.3203204870223999),\n",
       " ('아가', 0.30791905522346497),\n",
       " ('청주', 0.3052445650100708),\n",
       " ('할인', 0.30425143241882324),\n",
       " ('스푼', 0.30377405881881714),\n",
       " ('작성', 0.30159181356430054),\n",
       " ('공감', 0.2998657822608948),\n",
       " ('맛술', 0.2790175974369049),\n",
       " ('잎', 0.2788892686367035),\n",
       " ('식감', 0.2672884166240692),\n",
       " ('통후추', 0.26368245482444763),\n",
       " ('매실', 0.26293912529945374),\n",
       " ('살캔', 0.26154229044914246),\n",
       " ('얼마', 0.25505203008651733),\n",
       " ('보내다', 0.2521663010120392),\n",
       " ('반', 0.24980899691581726),\n",
       " ('꿀', 0.24892687797546387)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"단맛\"], negative=[\"싱겁다\"], topn=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3 유의미한 단어 찾기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_ = thrones2vec = w2v.Word2Vec(\n",
    "    sg = 1, seed = seed,\n",
    "    workers = num_workers,\n",
    "    size = num_features,\n",
    "    min_count = min_word_count,\n",
    "    window = context_size,\n",
    "    sample = downsampling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 151 ms, sys: 0 ns, total: 151 ms\n",
      "Wall time: 149 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models import word2vec\n",
    "data = Phrases(sentences=result[0])\n",
    "# data  = word2vec.LineSentence(script_file)\n",
    "# model = word2vec.Word2Vec(data, size=30, window=2, min_count=16, hs=1,\n",
    "#                           workers=4, iter=100, sg=1)\n",
    "# model.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-5db24ab36bdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model = word2vec.Word2Vec(data, size=30, window=2, min_count=16, hs=1,\n\u001b[0;32m----> 2\u001b[0;31m                           workers=4, iter=100, sg=1)\n\u001b[0m",
      "\u001b[0;32m~/Python/python/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, max_final_vocab)\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbow_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m             fast_version=FAST_VERSION)\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     def _do_train_epoch(self, corpus_file, thread_id, offset, cython_vocab, thread_private_mem, cur_epoch,\n",
      "\u001b[0;32m~/Python/python/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, ns_exponent, cbow_mean, min_alpha, compute_loss, fast_version, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You can't pass a generator as the sentences argument. Try a sequence.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m             self.train(\n\u001b[1;32m    761\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/python/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, sentences, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m         \"\"\"\n\u001b[1;32m    935\u001b[0m         total_words, corpus_count = self.vocabulary.scan_vocab(\n\u001b[0;32m--> 936\u001b[0;31m             sentences=sentences, corpus_file=corpus_file, progress_per=progress_per, trim_rule=trim_rule)\n\u001b[0m\u001b[1;32m    937\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/python/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mscan_vocab\u001b[0;34m(self, sentences, corpus_file, progress_per, workers, trim_rule)\u001b[0m\n\u001b[1;32m   1590\u001b[0m             \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLineSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m         \u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scan_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_per\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m         logger.info(\n",
      "\u001b[0;32m~/Python/python/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_scan_vocab\u001b[0;34m(self, sentences, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m   1559\u001b[0m         \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1560\u001b[0m         \u001b[0mchecked_string_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1561\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msentence_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1562\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchecked_string_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1563\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/python/lib/python3.6/site-packages/gensim/models/phrases.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         \"\"\"\n\u001b[0;32m--> 660\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_sentence2token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/python/lib/python3.6/site-packages/gensim/models/phrases.py\u001b[0m in \u001b[0;36m_sentence2token\u001b[0;34m(phrase_class, sentence)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \"\"\"\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0mis_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_is_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_single\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# if the input is an entire corpus (rather than a single sentence),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/python/lib/python3.6/site-packages/gensim/models/phrases.py\u001b[0m in \u001b[0;36m_is_single\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \"\"\"\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mobj_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0mtemp_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(data, size=30, window=2, min_count=16, \n",
    "                          workers=4, iter=100, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.phrases.Phrases"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가슴살 16\n",
      "계란 104\n",
      "닭 31\n",
      "장조림 342\n"
     ]
    }
   ],
   "source": [
    "# Post 문장 내용 확인하기\n",
    "w2v_temp    = result[0].splitlines() # \"\\n\" 기준으로 나눈다\n",
    "result_temp = []\n",
    "for _ in w2v_temp:\n",
    "    result_temp += _.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"11\".isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 블로그 내용의 저장 : ./w2v_script.txt\n"
     ]
    }
   ],
   "source": [
    "# 명사 Token 작업된 자료를 ssResport.txt 로 저장 \n",
    "script_file = './w2v_script.txt'\n",
    "with open(script_file, 'w', encoding='utf-8') as file:\n",
    "    file.write(result[0])\n",
    "    \n",
    "print(\"전처리 블로그 내용의 저장 : {}\".format(script_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1 Sentenced Text**\n",
    "**Word2vec** 을 만들기 위해서는 **문장 데이터로** 전처리가 필요하다\n",
    "1. **그냥 만든경우** 와, **문장을 선별한 경우를** 비교하여 성능 향상 시키기\n",
    "1. **핵심 Token 을 찾고**, 이를 바탕으로 word2vec 결과값 필터링 하기 **(Core 찾기가 우선)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 2 Vec 모델 파일 ./w2v_recipe.model 저장완료\n",
      "CPU times: user 4.63 s, sys: 103 ms, total: 4.73 s\n",
      "Wall time: 3.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models import word2vec\n",
    "data  = word2vec.LineSentence(script_file)\n",
    "model = word2vec.Word2Vec(data, size=30, window=2, min_count=16, hs=1,\n",
    "                          workers=4, iter=100, sg=1)\n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('닭가슴살', 0.725135326385498),\n",
       " ('이용한', 0.6401489973068237),\n",
       " ('메추리알', 0.6393377780914307),\n",
       " ('요리', 0.6060360670089722),\n",
       " ('오늘', 0.5656761527061462),\n",
       " ('법', 0.5500603318214417),\n",
       " ('오늘은', 0.5277817845344543),\n",
       " ('닭가슴살과', 0.4969708025455475),\n",
       " ('장조림을', 0.4929303228855133),\n",
       " ('글입니다', 0.4797065854072571),\n",
       " ('만드는', 0.4728950560092926),\n",
       " ('만들기', 0.46609869599342346),\n",
       " ('위해', 0.4544617533683777),\n",
       " ('먹는', 0.44983047246932983),\n",
       " ('좋아요', 0.4398360848426819),\n",
       " ('꽈리고추', 0.43841955065727234),\n",
       " ('다이어트', 0.4327726662158966),\n",
       " ('닭고기', 0.4298769235610962),\n",
       " ('마늘', 0.42846792936325073),\n",
       " ('닭가슴살을', 0.42231449484825134)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar([\"가슴살\", \"계란\", \"닭\", \"장조림\"], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('요리', 0.6024991273880005),\n",
       " ('사용', 0.3841325342655182),\n",
       " ('법', 0.3550140857696533),\n",
       " ('글입니다', 0.35304853320121765),\n",
       " ('꽈리고추', 0.35070517659187317),\n",
       " ('이제', 0.3504452109336853),\n",
       " ('간단하게', 0.3490484952926636),\n",
       " ('위해', 0.3488353192806244),\n",
       " ('먹기', 0.3451535701751709),\n",
       " ('오늘', 0.34397000074386597),\n",
       " ('다이어트', 0.3195529878139496),\n",
       " ('메추리알', 0.31017300486564636),\n",
       " ('마늘', 0.3066818416118622),\n",
       " ('반찬으로', 0.2982470989227295),\n",
       " ('맛있어요', 0.2916230857372284),\n",
       " ('레시피', 0.28354838490486145),\n",
       " ('오늘은', 0.271423876285553),\n",
       " ('내용', 0.26687198877334595),\n",
       " ('장조림을', 0.26355087757110596),\n",
       " ('좋아요', 0.25986653566360474),\n",
       " ('글에', 0.2506791651248932),\n",
       " ('넣어서', 0.23929870128631592),\n",
       " ('만들', 0.23346063494682312),\n",
       " ('이용한', 0.23234985768795013),\n",
       " ('안', 0.2303457111120224),\n",
       " ('저작자', 0.22936281561851501),\n",
       " ('좋아하는', 0.22905974090099335),\n",
       " ('물에', 0.22215133905410767),\n",
       " ('자주', 0.21964050829410553),\n",
       " ('하나', 0.20812654495239258)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar([\"가슴살\", \"계란\", \"닭\", \"장조림\"], \n",
    "                      negative=['닭가슴살', '닭가슴살과', '닭가슴살을'],\n",
    "                      topn=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>가슴살_계란_닭_장조림</td>\n",
       "      <td>반찬 볶음 조림.부드러운 닭가슴살 장조림 만들기.베리츄..2017.9.1.22 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>가슴살_굴소스_닭_볶음밥</td>\n",
       "      <td>아임닭 7기 종료.수비드 닭가슴살 요리 돈까스 볶음밥 만들기.주니호맘..2019.4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Query                                              Posts\n",
       "0   가슴살_계란_닭_장조림  반찬 볶음 조림.부드러운 닭가슴살 장조림 만들기.베리츄..2017.9.1.22 32...\n",
       "1  가슴살_굴소스_닭_볶음밥  아임닭 7기 종료.수비드 닭가슴살 요리 돈까스 볶음밥 만들기.주니호맘..2019.4..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "posts = pd.read_csv(\"data/naverPost_muyong.csv\")\n",
    "posts.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_temp = posts.loc[0]\n",
    "post_temp_query = post_temp.Query.split(\"_\")\n",
    "post_temp_list = post_temp.Posts.split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['가슴살', '계란', '닭', '장조림'],\n",
       " '반찬 볶음 조림.부드러운 닭가슴살 장조림 만들기.베리츄..2017.9.1.22 32.URL 복사.이웃추가.본문 기타 기능.번역보기.조림 밑반찬으로 대표적인 장조림.지방이 적고 단백질은 풍부한.닭가슴살.을 이용해 만들어봤어요.고기를 잘게 찢어 넣어 식감은 더 부드럽게.거기에.새송이버섯.과 제철을 맞이한.꽈리고추.까지 넉넉하게 넣어 만들었어요.꽈리고추는 일반 고추에 비해 쭈글쭈글하니 못생겼지만.비타민A와 C 등의 영양가가 풍부하고 매운맛이 덜해 조림이나 찜으로 먹기에 좋아요^^.닭가슴살장조림.닭가슴살 장조림 재료.조리시간 1시간 이내 ')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_temp_query, post_temp_list[0][:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post 내용의 필터링\n",
    "post_temp_list_blog = post_temp_list[0]\n",
    "post_temp_list_blog = post_temp_list_blog.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'반찬 볶음 조림.부드러운 닭가슴살 장조림 만들기.본문 기타 기능.조림 밑반찬으로 대표적인 장조림.지방이 적고 단백질은 풍부한.을 이용해 만들어봤어요.고기를 잘게 찢어 넣어 식감은 더 부드럽게.과 제철을 맞이한.까지 넉넉하게 넣어 만들었어요.꽈리고추는 일반 고추에 비해 쭈글쭈글하니 못생겼지만.비타민A와 C 등의 영양가가 풍부하고 매운맛이 덜해 조림이나 찜으로 먹기에 좋아요^^.닭가슴살 장조림 재료.조리시간 1시간 이내 난이도 중.생 닭가슴살 200g 물 1L 5컵 청주 2큰술 마늘 4쪽 생강 마늘 크기 1톨.새송이버섯 2개 꽈리고추 200g 약 3줌.양념 고기 육수 300ml 1.5컵 양조간장 100ml 0.5컵 꿀 2큰술 표고버섯가루 1 2큰술 후춧가루 약간.괄호 속 기재된 컵 은 종이컵 기준입니다.꿀 대신 올리고당으로 대체 가능합니다.고기 삶은 물은 양념에 사용할 거예요.끓는 물에 닭 가슴살 물 1L 5컵 마늘 4쪽 생강 1톨 청주 2큰술을 넣고 삶아주세요.센 불에서 끓어오르면 중불에서 뚜껑을 덮어 20 25분 정도 삶으면 됩니다.삶은 물은 버리지 마세요.삶는 시간이 생각보다 오래 걸리기 때문에 이때 재료 손질 및 양념을 만들어두는 것이 좋아요.닭이 충분히 익었는지 확인할 땐 젓가락을 이용해 찔러보세요.젓가락이 푹 들어가고 핏물이 빠져나오지 않으면 충분하게 익은 거예요.고기 삶는 동안 꽈리고추를 흐르는 물에 깨끗하게 씻은 뒤 꼭지를 제거해주세요.포크를 이용해 구멍을 내주세요.양념이 잘 배도록 구멍을 내주는 것인데 작은 건 한번 긴 건 두 번 정도 콕 찔러주면 됩니다.길이가 너무 긴 것은 반으로 썰어주세요.꽈리고추 고르는 법.전체적으로 윤기가 나며 꼭지가 단단한 것을 고르면 되는데요.이때 몸통이 단단한 것은 좀 더 맵고 말랑한 것은 매운맛이 덜하니 기호에 따라 고르셔요^^.새송이버섯은 가로로 2등분 한 뒤 0.3cm 두께로 슬라이스해주세요.쫄깃한 식감의 새송이버섯은 꼭 넣어주세요.계란보다 더 맛 좋은 별미랍니다.슬라이스하는 것이 번거롭다면 미니새송이버섯을 사용해도 좋아요.잘 삶아진 닭 가슴살은 먹기 좋게 고기 결대로 쭉쭉 찢어주세요.고기를 결대로 잘게 찢은 뒤 양념에 졸이면 조리시간을 단축할 수 있어요.식감도 퍽퍽하기보단 부드러워져요.닭가슴살 장조림 양념을 만들어주세요.고기 육수 300ml 1.5컵 양조간장 100ml 0.5컵 꿀 2큰술 표고버섯가루 1 2큰술 후춧가루 약간.꿀이 없다면 올리고당으로 넣어주세요.닭 삶은 물 안 버리셨죠.양념장 만들 때 물 대신 넣어주세요.저는 멸치나 다시마 육수 대신 넣어주는데요.따로 만들지 않아도 되니.간편하기도 하고 천연조미료 역할을 톡톡히 해내요.고기 꽈리고추 새송이버섯 양념을 냄비에 넣고 센 불에서 끓여주세요.끓어오르면 중불로 줄이고 뚜껑을 덮어 7분간 더 끓여주세요.가만히 둬도 간이 잘 배기 때문에 오래 끓여줄 필요가 없어요.30분 1시간 뒤면 양념이 더 배어들기 때문에 끓이는 시간은 10분 내로 해줘도 충분해요.한가지 반찬을 만들었지만 세 가지를 만든 것 같은 효과가.이렇게 만들어둔 닭가슴살 장조림은 기본 밑반찬으로 딱이에요.먹을 만큼 덜어 전자레인지에 따뜻하게 데워먹으면 더 부드럽고 맛이 좋아요.입맛이 없을 땐 맨밥 장조림 버터 1큰술 넣어 장조림버터비빔밥으로 즐겨도 좋겠죠.닭가슴살 장조림 만들기 핵심은요.고기 삶은 물은 버리지 않고 양념장 만들 때 사용하기.저작자 명시 필수.영리적 사용 불가.내용 변경 불가.저작자 명시 필수 영리적 사용 불가 내용 변경 불가.이 글에 공감한 블로거 열고 닫기.이 글에 댓글 단 블로거 열고 닫기.var gAdPostUnitIdForPC pc_blog_bottom.var gAdContentUnitIdForPC pc_blog_body'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 우선은 간단하게 기능을 추가한뒤\n",
    "# 식재료 Stemming 보완이 필요한 듯 ex) 후춧가루, 후추, 양념장 과 같은...\n",
    "#\n",
    "\".\".join([sent for sent in post_temp_list_blog   if len(re.findall(r\"\\w+\", sent)) >= 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1 Fast Text 모델링**\n",
    "https://pypi.org/project/fasttext/\n",
    "1. Gensim 보다 빠르다더라...\n",
    "1. https://github.com/facebookresearch/fastText\n",
    "1. **[Wiki 백과로 미리 훈련한 사전을 제공](https://dl.fbaipublicfiles.com/fasttext/vectors-aligned/wiki.ko.align.vec)**\n",
    "1. [실습 예제자료를 다운 루는 블로그](https://inspiringpeople.github.io/data%20analysis/word_embedding/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = \"\"\"반찬 볶음 조림.부드러운 닭가슴살 장조림 만들기.본문 기타 기능.조림 밑반찬으로 대표적인 장조림.\n",
    "지방이 적고 단백질은 풍부한.을 이용해 만들어봤어요.고기를 잘게 찢어 넣어 식감은 더 부드럽게.과 제철을 맞이한.\n",
    "까지 넉넉하게 넣어 만들었어요.꽈리고추는 일반 고추에 비해 쭈글쭈글하니 못생겼지만.\n",
    "비타민A와 C 등의 영양가가 풍부하고 매운맛이 덜해 조림이나 찜으로 먹기에 좋아요^^.닭가슴살 장조림 재료.\n",
    "조리시간 1시간 이내 난이도 중.생 닭가슴살 200g 물 1L 5컵 청주 2큰술 마늘 4쪽 생강 마늘 크기 1톨.\n",
    "새송이버섯 2개 꽈리고추 200g 약 3줌.양념 고기 육수 300ml 1.5컵 양조간장 100ml 0.5컵 꿀 2큰술 표고버섯가루 1 2큰술\n",
    "후춧가루 약간.괄호 속 기재된 컵 은 종이컵 기준입니다.꿀 대신 올리고당으로 대체 가능합니다.고기 삶은 물은 양념에 사용할 거예요.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "./w2v_script.txt cannot be opened for training!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-ff76e512e997>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# model = fasttext.skipgram('train.txt', 'model', lr=0.1, dim=300)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model = fasttext.skipgram(text_data, 'model', lr=0.1, dim=300)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_unsupervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'skipgram'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Python/python/lib/python3.6/site-packages/fasttext/FastText.py\u001b[0m in \u001b[0;36mtrain_unsupervised\u001b[0;34m(*kargs, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_build_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FastText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m     \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ./w2v_script.txt cannot be opened for training!"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "script_file = './w2v_script.txt'\n",
    "# model = fasttext.skipgram(script_file, 'model', lr=0.1, dim=300)\n",
    "# model = fasttext.skipgram('train.txt', 'model', lr=0.1, dim=300)\n",
    "# model = fasttext.skipgram(text_data, 'model', lr=0.1, dim=300)\n",
    "model = fasttext.train_unsupervised(script_file, model='skipgram', dim=300, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "data.txt cannot be opened for training!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-c11e490274be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Skipgram model :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_unsupervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'skipgram'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# or, cbow model :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/python/lib/python3.6/site-packages/fasttext/FastText.py\u001b[0m in \u001b[0;36mtrain_unsupervised\u001b[0;34m(*kargs, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_build_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FastText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m     \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: data.txt cannot be opened for training!"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "# Skipgram model :\n",
    "model = fasttext.train_unsupervised('data.txt', model='skipgram')\n",
    "\n",
    "# or, cbow model :\n",
    "model = fasttext.train_unsupervised('data.txt', model='cbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-d675cca440a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# list of words in dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'king'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get the vector of the word 'king'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print(model.words)   # list of words in dictionary\n",
    "print(model['king']) # get the vector of the word 'king'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습결과 Model 로 저장하기\n",
    "model.save_model(\"model_filename.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 Model 객체 불러오기\n",
    "model = fasttext.load_model(\"model_filename.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "model = fasttext.train_supervised('data.train.txt')\n",
    "print(model.words)\n",
    "print(model.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.words         # equivalent to model.get_words()\n",
    "model.labels        # equivalent to model.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model['king']       # equivalent to model.get_word_vector('king')\n",
    "'king' in model     # equivalent to `'king' in model.get_words()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 Token 의 가중치 확인하기\n",
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('test.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 모델을 활용하여 판단하기\n",
    "model.predict(\"Which baking dish is best to bake a banana bread ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력할 결과값을 사용자가 지정 가능 (k=3)\n",
    "model.predict(\"Which baking dish is best to bake a banana bread ?\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to predict more than one sentence you can pass an array of strings \n",
    "model.predict([\"Which baking dish is best to bake a banana bread ?\", \"Why not put knives in the dishwasher?\"], k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the previously trained `model` object, call :\n",
    "model.quantize(input='data.train.txt', retrain=True)\n",
    "\n",
    "# then display results and save the new model :\n",
    "print_results(*model.test(valid_data))\n",
    "model.save_model(\"model_filename.ftz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1 Naver Link 목록**\n",
    "OpenAPI 로 수집한 결과값 저장된 목록 List 원본의 수정보완\n",
    "1. Naver OPEN API 결과 **Token 이 유효값인지** 확인 가능했다 (Oh!!)\n",
    "1. 네이버 블로그 목록만 정리한 DataBase 만들기\n",
    "1. 목록을 4개로 나워서 2개의 서버에서 돌리며 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>가슴살_계란_닭_장조림</td>\n",
       "      <td>반찬 볶음 조림.부드러운 닭가슴살 장조림 만들기.베리츄..2017.9.1.22 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>간장_불고기_제육_파채</td>\n",
       "      <td>오늘의 식탁.[반조리 밥아저씨] 12월 12일 식탁 버섯제육간장불고기 파채 감자고추...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>감자_국_수제비</td>\n",
       "      <td>나의이야기.아침에 먹고 남은 감자국으로 수제비 만드는법 하기 위해 수제비 반죽만들기...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Query                                              Posts\n",
       "0  가슴살_계란_닭_장조림  반찬 볶음 조림.부드러운 닭가슴살 장조림 만들기.베리츄..2017.9.1.22 32...\n",
       "1  간장_불고기_제육_파채  오늘의 식탁.[반조리 밥아저씨] 12월 12일 식탁 버섯제육간장불고기 파채 감자고추...\n",
       "2      감자_국_수제비  나의이야기.아침에 먹고 남은 감자국으로 수제비 만드는법 하기 위해 수제비 반죽만들기..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/naver_posts_sample.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " '가슴살 간장 감자 강정 겉절이 계란 계란말이 고추 고추장 골뱅이 국 굴 김치 깨 꼬치 꽃게 너비아니 달래 닭 데리야끼 도라지생채 돈 돈육 된장국 두부 들깨 떡국 만두 매콤 무 무침 물 미나리 미소 미역 버섯 볶음 부추 불고기 브로콜리 사골 사태 상추 새송이 새우젓 샐러드 소고기 소스 수제비 순두부 시금치나물 야채 양상추 양파 어묵 엿 오이 오징어 우동 유자 장국 장조림 장포 적 제육 조림 짬뽕 찜 찹쌀 채 채소 청경채 초무침 치어 치즈 칠리 콩나물 탕 탕수 파채 팽이 해물탕 햄 황도 후랑크 후르츠')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "querys = sorted(list(set(\"_\".join(df.Query.tolist()).split(\"_\"))))\n",
    "print(len(querys)), \" \".join(querys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1 Naver Link 목록**\n",
    "OpenAPI 로 수집한 결과값 저장된 목록 List 원본의 수정보완\n",
    "1. Naver OPEN API 결과 **Token 이 유효값인지** 확인 가능했다 (Oh!!)\n",
    "1. 네이버 블로그 목록만 정리한 DataBase 만들기\n",
    "1. 목록을 4개로 나워서 2개의 서버에서 돌리며 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
